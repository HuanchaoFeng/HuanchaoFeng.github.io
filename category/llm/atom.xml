<?xml version="1.0"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <id>http://example.com</id>
    <title>Phoenix • Posts by &#34;llm&#34; category</title>
    <link href="http://example.com" />
    <updated>2025-05-16T16:37:02.000Z</updated>
    <category term="LLM" />
    <category term="concept" />
    <category term="Bert" />
    <category term="GPT" />
    <category term="resume" />
    <category term="transformer" />
    <category term="datalinkx" />
    <entry>
        <id>http://example.com/2025/05/17/GPT-BertBuild/</id>
        <title>GPT&amp;BertBuild</title>
        <link rel="alternate" href="http://example.com/2025/05/17/GPT-BertBuild/"/>
        <content type="html">&lt;h2 id=&#34;生成式预训练语言模型gpt&#34;&gt;&lt;a class=&#34;markdownIt-Anchor&#34; href=&#34;#生成式预训练语言模型gpt&#34;&gt;#&lt;/a&gt; 生成式预训练语言模型 GPT&lt;/h2&gt;
&lt;p&gt;GPT 的模型结构，由多个 transformer 的 decoder 组成，结构如下：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;image1.png&#34; alt=&#34;image1&#34;&gt;&lt;/p&gt;
&lt;p&gt;该模型利用的是 transformer 的解码器部分，训练和推理的过程是类似的，12 层 transformer 模块都在做类似的事情，到最后一层后输出预测的分数（映射到词分类中，得到预测的分数 / 置信度）&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;有监督下游任务微调：&lt;/p&gt;
&lt;p&gt;在进行下游任务微调时，仅使用 GPT 的最后一层的最后一个词的隐藏状态，同个全连接层映射到标签空间。因为每个词的隐藏状态都聚合了左侧所有历史词的信息，因此最后一个词的隐藏状态天然编码了整个序列的全局语义。&lt;/p&gt;
&lt;p&gt;同时再进行微调的时候，可能会出现模型遗忘预训练阶段学习的通用只是表示，损失通用与泛化能力，出现灾难性遗忘的问题，所以通常采用混合预训练任务损失和下游微调损失缓解这一问题，Loss Function 如下:&lt;br&gt;
&lt;img src=&#34;image2.png&#34; alt=&#34;image2&#34;&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;bert模型构建&#34;&gt;&lt;a class=&#34;markdownIt-Anchor&#34; href=&#34;#bert模型构建&#34;&gt;#&lt;/a&gt; Bert 模型构建&lt;/h2&gt;
&lt;p&gt;Bert 模型一般是基于 Transformer 的编码器部分构建的，是一个相当于完形填空 (mask) 的模型，是考虑双向的模型（同时利用两侧信息）&lt;/p&gt;
&lt;p&gt;例子：&lt;/p&gt;
&lt;figure class=&#34;highlight python&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;15&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;16&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;17&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;18&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;19&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;input&lt;/span&gt;:the cat site on the mat&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;tokenizer(分词):（假设不加入CLS标记和SEP标记）&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    code:[&lt;span class=&#34;number&#34;&gt;1996&lt;/span&gt;,&lt;span class=&#34;number&#34;&gt;4248&lt;/span&gt;,&lt;span class=&#34;number&#34;&gt;2825&lt;/span&gt;,&lt;span class=&#34;number&#34;&gt;2007&lt;/span&gt;,&lt;span class=&#34;number&#34;&gt;1996&lt;/span&gt;,&lt;span class=&#34;number&#34;&gt;3829&lt;/span&gt;,&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;,&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;] &lt;span class=&#34;comment&#34;&gt;# 0为pad的编码，max假设为8&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    attention_mask:[&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;,&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;,&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;,&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;,&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;,&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;,&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;] &lt;span class=&#34;comment&#34;&gt;# 0表示填充的位置&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;random mask:选取到了site作为掩码，替换为mask的编码-&amp;gt;&lt;span class=&#34;number&#34;&gt;103&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;	code:[&lt;span class=&#34;number&#34;&gt;1996&lt;/span&gt;,&lt;span class=&#34;number&#34;&gt;4248&lt;/span&gt;,&lt;span class=&#34;number&#34;&gt;103&lt;/span&gt;,&lt;span class=&#34;number&#34;&gt;2007&lt;/span&gt;,&lt;span class=&#34;number&#34;&gt;1996&lt;/span&gt;,&lt;span class=&#34;number&#34;&gt;3829&lt;/span&gt;,&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;,&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;]&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    attention_mask:[&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;,&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;,&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;,&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;,&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;,&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;,&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;,&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;]&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    label:[-&lt;span class=&#34;number&#34;&gt;100&lt;/span&gt;,-&lt;span class=&#34;number&#34;&gt;100&lt;/span&gt;,&lt;span class=&#34;number&#34;&gt;2825&lt;/span&gt;,-&lt;span class=&#34;number&#34;&gt;100&lt;/span&gt;,-&lt;span class=&#34;number&#34;&gt;100&lt;/span&gt;,-&lt;span class=&#34;number&#34;&gt;100&lt;/span&gt;,-&lt;span class=&#34;number&#34;&gt;100&lt;/span&gt;,-&lt;span class=&#34;number&#34;&gt;100&lt;/span&gt;] &lt;span class=&#34;comment&#34;&gt;#这个是用于计算掩码的真实标签，-100表示不需要计算，只保留被掩码的位置&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;train:&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    将上述数据送入Bert模型中&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;output:&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    [&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        [..,..,..,..,],&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        [..,..,..,..,],&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        [..,..,..,..,], &lt;span class=&#34;comment&#34;&gt;#取第二个位置进行计算交叉熵&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        [..,..,..,..,],&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        ........&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    ]&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;训练过程：加载 dataset, 切分 traindataset 和 testdataset --&amp;gt; 用 traindataset 训练词元分析器，形成 vocab 词表 --&amp;gt; 加载预训练词元分析器 --&amp;gt; 分词序列 --&amp;gt; 加载随即权重的 BERT 模型，设置掩码比例，进行训练，下面是代码训练过程：&lt;/p&gt;
&lt;p&gt;dataset 获取与镜像设置：&lt;/p&gt;
&lt;figure class=&#34;highlight python&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;#下载数据集：&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;pip install huggingface_hub&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;huggingface-cli download --repo-&lt;span class=&#34;built_in&#34;&gt;type&lt;/span&gt; dataset legacy-datasets/wikipedia  --local-&lt;span class=&#34;built_in&#34;&gt;dir&lt;/span&gt; wikipedia&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# mirror&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;export HF_ENDPOINT=https://hf-mirror.com&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;environment (有部分可能不需要）:&lt;/p&gt;
&lt;figure class=&#34;highlight python&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;15&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;16&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;17&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;18&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;19&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;20&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;21&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;22&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;23&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;24&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;25&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;26&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;27&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;28&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;29&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;30&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;31&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;32&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;33&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;34&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;35&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;36&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;37&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;38&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;39&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;40&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;41&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;42&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;43&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;44&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;45&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;46&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;47&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;48&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;49&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;50&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;51&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;52&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;53&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;54&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;55&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;56&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;57&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;58&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;59&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;60&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;61&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;62&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;63&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;64&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;65&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;66&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;67&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;68&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;69&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;70&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;71&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;72&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;73&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;74&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;75&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;76&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;77&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;78&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;79&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;80&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;81&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;82&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;83&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;84&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;85&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;86&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;channels:&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;  - defaults&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;dependencies:&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;  - _libgcc_mutex=&lt;span class=&#34;number&#34;&gt;0.1&lt;/span&gt;=main&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;  - _openmp_mutex=&lt;span class=&#34;number&#34;&gt;5.1&lt;/span&gt;=1_gnu&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;  - bzip2=&lt;span class=&#34;number&#34;&gt;1.0&lt;/span&gt;&lt;span class=&#34;number&#34;&gt;.8&lt;/span&gt;=h5eee18b_6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;  - ca-certificates=&lt;span class=&#34;number&#34;&gt;2025.2&lt;/span&gt;&lt;span class=&#34;number&#34;&gt;.25&lt;/span&gt;=h06a4308_0&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;  - expat=&lt;span class=&#34;number&#34;&gt;2.7&lt;/span&gt;&lt;span class=&#34;number&#34;&gt;.1&lt;/span&gt;=h6a678d5_0&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;  - ld_impl_linux-&lt;span class=&#34;number&#34;&gt;64&lt;/span&gt;=&lt;span class=&#34;number&#34;&gt;2.40&lt;/span&gt;=h12ee557_0&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;  - libffi=&lt;span class=&#34;number&#34;&gt;3.4&lt;/span&gt;&lt;span class=&#34;number&#34;&gt;.4&lt;/span&gt;=h6a678d5_1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;  - libgcc-ng=&lt;span class=&#34;number&#34;&gt;11.2&lt;/span&gt;&lt;span class=&#34;number&#34;&gt;.0&lt;/span&gt;=h1234567_1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;  - libgomp=&lt;span class=&#34;number&#34;&gt;11.2&lt;/span&gt;&lt;span class=&#34;number&#34;&gt;.0&lt;/span&gt;=h1234567_1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;  - libstdcxx-ng=&lt;span class=&#34;number&#34;&gt;11.2&lt;/span&gt;&lt;span class=&#34;number&#34;&gt;.0&lt;/span&gt;=h1234567_1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;  - libuuid=&lt;span class=&#34;number&#34;&gt;1.41&lt;/span&gt;&lt;span class=&#34;number&#34;&gt;.5&lt;/span&gt;=h5eee18b_0&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;  - ncurses=&lt;span class=&#34;number&#34;&gt;6.4&lt;/span&gt;=h6a678d5_0&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;  - openssl=&lt;span class=&#34;number&#34;&gt;3.0&lt;/span&gt;&lt;span class=&#34;number&#34;&gt;.16&lt;/span&gt;=h5eee18b_0&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;  - pip=&lt;span class=&#34;number&#34;&gt;25.1&lt;/span&gt;=pyhc872135_2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;  - python=&lt;span class=&#34;number&#34;&gt;3.12&lt;/span&gt;&lt;span class=&#34;number&#34;&gt;.9&lt;/span&gt;=h5148396_0&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;  - readline=&lt;span class=&#34;number&#34;&gt;8.2&lt;/span&gt;=h5eee18b_0&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;  - setuptools=&lt;span class=&#34;number&#34;&gt;78.1&lt;/span&gt;&lt;span class=&#34;number&#34;&gt;.1&lt;/span&gt;=py312h06a4308_0&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;  - sqlite=&lt;span class=&#34;number&#34;&gt;3.45&lt;/span&gt;&lt;span class=&#34;number&#34;&gt;.3&lt;/span&gt;=h5eee18b_0&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;  - tk=&lt;span class=&#34;number&#34;&gt;8.6&lt;/span&gt;&lt;span class=&#34;number&#34;&gt;.14&lt;/span&gt;=h39e8969_0&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;  - wheel=&lt;span class=&#34;number&#34;&gt;0.45&lt;/span&gt;&lt;span class=&#34;number&#34;&gt;.1&lt;/span&gt;=py312h06a4308_0&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;  - xz=&lt;span class=&#34;number&#34;&gt;5.6&lt;/span&gt;&lt;span class=&#34;number&#34;&gt;.4&lt;/span&gt;=h5eee18b_1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;  - zlib=&lt;span class=&#34;number&#34;&gt;1.2&lt;/span&gt;&lt;span class=&#34;number&#34;&gt;.13&lt;/span&gt;=h5eee18b_1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;  - pip:&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;      - accelerate==&lt;span class=&#34;number&#34;&gt;0.26&lt;/span&gt;&lt;span class=&#34;number&#34;&gt;.0&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;      - aiohappyeyeballs==&lt;span class=&#34;number&#34;&gt;2.6&lt;/span&gt;&lt;span class=&#34;number&#34;&gt;.1&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;      - aiohttp==&lt;span class=&#34;number&#34;&gt;3.11&lt;/span&gt;&lt;span class=&#34;number&#34;&gt;.18&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;      - aiosignal==&lt;span class=&#34;number&#34;&gt;1.3&lt;/span&gt;&lt;span class=&#34;number&#34;&gt;.2&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;      - attrs==&lt;span class=&#34;number&#34;&gt;25.3&lt;/span&gt;&lt;span class=&#34;number&#34;&gt;.0&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;      - certifi==&lt;span class=&#34;number&#34;&gt;2025.4&lt;/span&gt;&lt;span class=&#34;number&#34;&gt;.26&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;      - charset-normalizer==&lt;span class=&#34;number&#34;&gt;3.4&lt;/span&gt;&lt;span class=&#34;number&#34;&gt;.2&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;      - datasets==&lt;span class=&#34;number&#34;&gt;3.6&lt;/span&gt;&lt;span class=&#34;number&#34;&gt;.0&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;      - dill==&lt;span class=&#34;number&#34;&gt;0.3&lt;/span&gt;&lt;span class=&#34;number&#34;&gt;.8&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;      - filelock==&lt;span class=&#34;number&#34;&gt;3.18&lt;/span&gt;&lt;span class=&#34;number&#34;&gt;.0&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;      - frozenlist==&lt;span class=&#34;number&#34;&gt;1.6&lt;/span&gt;&lt;span class=&#34;number&#34;&gt;.0&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;      - fsspec==&lt;span class=&#34;number&#34;&gt;2025.3&lt;/span&gt;&lt;span class=&#34;number&#34;&gt;.0&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;      - huggingface-hub==&lt;span class=&#34;number&#34;&gt;0.31&lt;/span&gt;&lt;span class=&#34;number&#34;&gt;.2&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;      - idna==&lt;span class=&#34;number&#34;&gt;3.10&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;      - jinja2==&lt;span class=&#34;number&#34;&gt;3.1&lt;/span&gt;&lt;span class=&#34;number&#34;&gt;.6&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;      - markupsafe==&lt;span class=&#34;number&#34;&gt;3.0&lt;/span&gt;&lt;span class=&#34;number&#34;&gt;.2&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;      - mpmath==&lt;span class=&#34;number&#34;&gt;1.3&lt;/span&gt;&lt;span class=&#34;number&#34;&gt;.0&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;      - multidict==&lt;span class=&#34;number&#34;&gt;6.4&lt;/span&gt;&lt;span class=&#34;number&#34;&gt;.3&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;      - multiprocess==&lt;span class=&#34;number&#34;&gt;0.70&lt;/span&gt;&lt;span class=&#34;number&#34;&gt;.16&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;      - mwparserfromhell==&lt;span class=&#34;number&#34;&gt;0.6&lt;/span&gt;&lt;span class=&#34;number&#34;&gt;.6&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;      - networkx==&lt;span class=&#34;number&#34;&gt;3.4&lt;/span&gt;&lt;span class=&#34;number&#34;&gt;.2&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;      - numpy==&lt;span class=&#34;number&#34;&gt;2.2&lt;/span&gt;&lt;span class=&#34;number&#34;&gt;.5&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;      - nvidia-cublas-cu12==&lt;span class=&#34;number&#34;&gt;12.6&lt;/span&gt;&lt;span class=&#34;number&#34;&gt;.4&lt;/span&gt;&lt;span class=&#34;number&#34;&gt;.1&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;      - nvidia-cuda-cupti-cu12==&lt;span class=&#34;number&#34;&gt;12.6&lt;/span&gt;&lt;span class=&#34;number&#34;&gt;.80&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;      - nvidia-cuda-nvrtc-cu12==&lt;span class=&#34;number&#34;&gt;12.6&lt;/span&gt;&lt;span class=&#34;number&#34;&gt;.77&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;      - nvidia-cuda-runtime-cu12==&lt;span class=&#34;number&#34;&gt;12.6&lt;/span&gt;&lt;span class=&#34;number&#34;&gt;.77&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;      - nvidia-cudnn-cu12==&lt;span class=&#34;number&#34;&gt;9.5&lt;/span&gt;&lt;span class=&#34;number&#34;&gt;.1&lt;/span&gt;&lt;span class=&#34;number&#34;&gt;.17&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;      - nvidia-cufft-cu12==&lt;span class=&#34;number&#34;&gt;11.3&lt;/span&gt;&lt;span class=&#34;number&#34;&gt;.0&lt;/span&gt;&lt;span class=&#34;number&#34;&gt;.4&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;      - nvidia-cufile-cu12==&lt;span class=&#34;number&#34;&gt;1.11&lt;/span&gt;&lt;span class=&#34;number&#34;&gt;.1&lt;/span&gt;&lt;span class=&#34;number&#34;&gt;.6&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;      - nvidia-curand-cu12==&lt;span class=&#34;number&#34;&gt;10.3&lt;/span&gt;&lt;span class=&#34;number&#34;&gt;.7&lt;/span&gt;&lt;span class=&#34;number&#34;&gt;.77&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;      - nvidia-cusolver-cu12==&lt;span class=&#34;number&#34;&gt;11.7&lt;/span&gt;&lt;span class=&#34;number&#34;&gt;.1&lt;/span&gt;&lt;span class=&#34;number&#34;&gt;.2&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;      - nvidia-cusparse-cu12==&lt;span class=&#34;number&#34;&gt;12.5&lt;/span&gt;&lt;span class=&#34;number&#34;&gt;.4&lt;/span&gt;&lt;span class=&#34;number&#34;&gt;.2&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;      - nvidia-cusparselt-cu12==&lt;span class=&#34;number&#34;&gt;0.6&lt;/span&gt;&lt;span class=&#34;number&#34;&gt;.3&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;      - nvidia-nccl-cu12==&lt;span class=&#34;number&#34;&gt;2.26&lt;/span&gt;&lt;span class=&#34;number&#34;&gt;.2&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;      - nvidia-nvjitlink-cu12==&lt;span class=&#34;number&#34;&gt;12.6&lt;/span&gt;&lt;span class=&#34;number&#34;&gt;.85&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;      - nvidia-nvtx-cu12==&lt;span class=&#34;number&#34;&gt;12.6&lt;/span&gt;&lt;span class=&#34;number&#34;&gt;.77&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;      - packaging==&lt;span class=&#34;number&#34;&gt;25.0&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;      - pandas==&lt;span class=&#34;number&#34;&gt;2.2&lt;/span&gt;&lt;span class=&#34;number&#34;&gt;.3&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;      - propcache==&lt;span class=&#34;number&#34;&gt;0.3&lt;/span&gt;&lt;span class=&#34;number&#34;&gt;.1&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;      - psutil==&lt;span class=&#34;number&#34;&gt;7.0&lt;/span&gt;&lt;span class=&#34;number&#34;&gt;.0&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;      - pyarrow==&lt;span class=&#34;number&#34;&gt;20.0&lt;/span&gt;&lt;span class=&#34;number&#34;&gt;.0&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;      - python-dateutil==&lt;span class=&#34;number&#34;&gt;2.9&lt;/span&gt;&lt;span class=&#34;number&#34;&gt;.0&lt;/span&gt;.post0&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;      - pytz==&lt;span class=&#34;number&#34;&gt;2025.2&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;      - pyyaml==&lt;span class=&#34;number&#34;&gt;6.0&lt;/span&gt;&lt;span class=&#34;number&#34;&gt;.2&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;      - regex==&lt;span class=&#34;number&#34;&gt;2024.11&lt;/span&gt;&lt;span class=&#34;number&#34;&gt;.6&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;      - requests==&lt;span class=&#34;number&#34;&gt;2.32&lt;/span&gt;&lt;span class=&#34;number&#34;&gt;.3&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;      - safetensors==&lt;span class=&#34;number&#34;&gt;0.5&lt;/span&gt;&lt;span class=&#34;number&#34;&gt;.3&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;      - six==&lt;span class=&#34;number&#34;&gt;1.17&lt;/span&gt;&lt;span class=&#34;number&#34;&gt;.0&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;      - sympy==&lt;span class=&#34;number&#34;&gt;1.14&lt;/span&gt;&lt;span class=&#34;number&#34;&gt;.0&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;      - tokenizers==&lt;span class=&#34;number&#34;&gt;0.21&lt;/span&gt;&lt;span class=&#34;number&#34;&gt;.1&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;      - torch==&lt;span class=&#34;number&#34;&gt;2.7&lt;/span&gt;&lt;span class=&#34;number&#34;&gt;.0&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;      - tqdm==&lt;span class=&#34;number&#34;&gt;4.67&lt;/span&gt;&lt;span class=&#34;number&#34;&gt;.1&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;      - transformers==&lt;span class=&#34;number&#34;&gt;4.51&lt;/span&gt;&lt;span class=&#34;number&#34;&gt;.3&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;      - triton==&lt;span class=&#34;number&#34;&gt;3.3&lt;/span&gt;&lt;span class=&#34;number&#34;&gt;.0&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;      - typing-extensions==&lt;span class=&#34;number&#34;&gt;4.13&lt;/span&gt;&lt;span class=&#34;number&#34;&gt;.2&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;      - tzdata==&lt;span class=&#34;number&#34;&gt;2025.2&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;      - urllib3==&lt;span class=&#34;number&#34;&gt;2.4&lt;/span&gt;&lt;span class=&#34;number&#34;&gt;.0&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;      - xxhash==&lt;span class=&#34;number&#34;&gt;3.5&lt;/span&gt;&lt;span class=&#34;number&#34;&gt;.0&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;      - yarl==&lt;span class=&#34;number&#34;&gt;1.20&lt;/span&gt;&lt;span class=&#34;number&#34;&gt;.0&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;figure class=&#34;highlight python&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;15&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;16&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;17&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;18&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;19&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;20&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;21&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;22&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;23&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;24&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;25&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;26&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;27&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;28&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;29&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;30&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;31&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;32&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;33&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;34&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;35&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;36&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;37&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;38&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;39&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;40&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;41&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;42&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;43&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;44&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;45&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;46&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;47&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;48&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;49&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;50&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;51&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;52&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;53&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;54&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;55&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;56&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;57&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;58&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;59&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;60&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;61&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;62&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;63&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;64&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;65&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;66&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;67&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;68&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;69&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;70&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;71&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;72&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;73&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;74&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;75&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;76&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;77&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;78&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;79&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;80&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;81&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;82&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;83&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;84&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;85&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;86&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;87&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;88&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;89&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;90&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;91&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;92&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;93&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;94&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;95&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;96&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;97&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;98&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;99&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;100&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;101&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;102&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;103&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;104&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;105&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;106&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;107&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;108&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;109&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;110&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;111&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;112&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;113&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;114&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;115&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;116&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;117&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;118&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;119&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;120&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;121&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;122&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;123&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;124&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;125&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;126&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;127&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;128&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;129&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;130&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;131&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;132&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;133&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;134&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;135&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;136&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;137&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;138&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;139&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;140&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;141&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;142&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;143&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;144&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;145&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;146&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;147&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;148&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;149&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;150&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;151&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;152&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;153&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;154&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;155&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;156&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;157&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;158&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;159&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;160&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;161&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;162&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;163&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;164&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;165&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;166&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;167&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;168&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;169&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;170&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;171&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;from&lt;/span&gt; transformers &lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; BertTokenizerFast,BertConfig,BertForMaskedLM,DataCollatorForLanguageModeling,TrainingArguments,Trainer&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;from&lt;/span&gt; datasets &lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; load_dataset&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;from&lt;/span&gt; tokenizers &lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; BertWordPieceTokenizer&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; torch&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; os&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; json&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;from&lt;/span&gt; itertools &lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; chain&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; os&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;os.environ[&lt;span class=&#34;string&#34;&gt;&amp;#x27;CUDA_VISIBLE_DEVICES&amp;#x27;&lt;/span&gt;] = &lt;span class=&#34;string&#34;&gt;&amp;#x27;2&amp;#x27;&lt;/span&gt; &lt;span class=&#34;comment&#34;&gt;# 这个得加，多gpu跑的话会有问题&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 加载本地数据&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;wiki = load_dataset(&lt;span class=&#34;string&#34;&gt;&amp;quot;/data/hcfeng/learnLLM/wikipedia&amp;quot;&lt;/span&gt;, &lt;span class=&#34;string&#34;&gt;&amp;quot;20220301.en&amp;quot;&lt;/span&gt;, split=&lt;span class=&#34;string&#34;&gt;&amp;quot;train&amp;quot;&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;#仅保留text列&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;wiki = wiki.remove_columns([col &lt;span class=&#34;keyword&#34;&gt;for&lt;/span&gt; col &lt;span class=&#34;keyword&#34;&gt;in&lt;/span&gt; wiki.column_names &lt;span class=&#34;keyword&#34;&gt;if&lt;/span&gt; col!=&lt;span class=&#34;string&#34;&gt;&amp;quot;text&amp;quot;&lt;/span&gt;])&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;#切割数据&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;dataset = wiki&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;d = dataset.train_test_split(train_size=&lt;span class=&#34;number&#34;&gt;0.9&lt;/span&gt;,test_size=&lt;span class=&#34;number&#34;&gt;0.1&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;dataset_to_text&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;dataset,filename&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    outpur_path=&lt;span class=&#34;string&#34;&gt;&amp;quot;/data/hcfeng/learnLLM/TrainBert/small_dataset/&amp;quot;&lt;/span&gt;+filename &lt;span class=&#34;comment&#34;&gt;#拼接地址&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;with&lt;/span&gt; &lt;span class=&#34;built_in&#34;&gt;open&lt;/span&gt;(outpur_path,&lt;span class=&#34;string&#34;&gt;&amp;#x27;w&amp;#x27;&lt;/span&gt;) &lt;span class=&#34;keyword&#34;&gt;as&lt;/span&gt; f:&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;keyword&#34;&gt;for&lt;/span&gt; t &lt;span class=&#34;keyword&#34;&gt;in&lt;/span&gt; dataset[&lt;span class=&#34;string&#34;&gt;&amp;#x27;text&amp;#x27;&lt;/span&gt;]:&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            &lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(t,file=f)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;dataset_to_text(d[&lt;span class=&#34;string&#34;&gt;&amp;#x27;train&amp;#x27;&lt;/span&gt;],&lt;span class=&#34;string&#34;&gt;&amp;#x27;train.txt&amp;#x27;&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;dataset_to_text(d[&lt;span class=&#34;string&#34;&gt;&amp;#x27;test&amp;#x27;&lt;/span&gt;],&lt;span class=&#34;string&#34;&gt;&amp;#x27;test.txt&amp;#x27;&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;special_tokens = [&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;string&#34;&gt;&amp;quot;[PAD]&amp;quot;&lt;/span&gt;, &lt;span class=&#34;string&#34;&gt;&amp;quot;[UNK]&amp;quot;&lt;/span&gt;, &lt;span class=&#34;string&#34;&gt;&amp;quot;[CLS]&amp;quot;&lt;/span&gt;, &lt;span class=&#34;string&#34;&gt;&amp;quot;[SEP]&amp;quot;&lt;/span&gt;, &lt;span class=&#34;string&#34;&gt;&amp;quot;[MASK]&amp;quot;&lt;/span&gt;, &lt;span class=&#34;string&#34;&gt;&amp;quot;&amp;lt;S&amp;gt;&amp;quot;&lt;/span&gt;, &lt;span class=&#34;string&#34;&gt;&amp;quot;&amp;lt;T&amp;gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;]&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 如果根据训练和测试两个集合训练词元分析器，则需要修改files&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# files = [&amp;quot;train.txt&amp;quot;, &amp;quot;test.txt&amp;quot;]&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 仅根据训练集合训练词元分析器&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;files = [&lt;span class=&#34;string&#34;&gt;&amp;quot;/data/hcfeng/learnLLM/TrainBert/small_dataset/train.txt&amp;quot;&lt;/span&gt;]&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# BERT中采用的默认词表大小为30522，可以随意修改&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;vocab_size = &lt;span class=&#34;number&#34;&gt;30522&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 最大序列长度，该值越小，训练速度越快&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;max_length = &lt;span class=&#34;number&#34;&gt;512&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 是否将长样本截断&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;truncate_longer_samples = &lt;span class=&#34;literal&#34;&gt;True&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 初始化WordPiece词元分析器&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;tokenizer = BertWordPieceTokenizer()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 训练词元分析器，设定的 vocab_size 是最大允许值，但实际生成的词表大小可能更小&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;tokenizer.train(files=files, vocab_size=vocab_size, special_tokens=special_tokens) &lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 允许截断达到最大512个词元&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;tokenizer.enable_truncation(max_length=max_length)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;model_path = &lt;span class=&#34;string&#34;&gt;&amp;quot;/data/hcfeng/learnLLM/TrainBert/small_pretrained-bert&amp;quot;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 如果文件夹不存在，则先创建文件夹&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;if&lt;/span&gt; &lt;span class=&#34;keyword&#34;&gt;not&lt;/span&gt; os.path.isdir(model_path):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    os.mkdir(model_path)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 保存词元分析器模型&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;tokenizer.save_model(model_path)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 将一些词元分析器中的配置保存到配置文件，包括特殊词元、转换为小写、最大序列长度等&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;with&lt;/span&gt; &lt;span class=&#34;built_in&#34;&gt;open&lt;/span&gt;(os.path.join(model_path, &lt;span class=&#34;string&#34;&gt;&amp;quot;config.json&amp;quot;&lt;/span&gt;), &lt;span class=&#34;string&#34;&gt;&amp;quot;w&amp;quot;&lt;/span&gt;) &lt;span class=&#34;keyword&#34;&gt;as&lt;/span&gt; f:&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    tokenizer_cfg = &amp;#123;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;string&#34;&gt;&amp;quot;do_lower_case&amp;quot;&lt;/span&gt;: &lt;span class=&#34;literal&#34;&gt;True&lt;/span&gt;,&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;string&#34;&gt;&amp;quot;unk_token&amp;quot;&lt;/span&gt;: &lt;span class=&#34;string&#34;&gt;&amp;quot;[UNK]&amp;quot;&lt;/span&gt;,&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;string&#34;&gt;&amp;quot;sep_token&amp;quot;&lt;/span&gt;: &lt;span class=&#34;string&#34;&gt;&amp;quot;[SEP]&amp;quot;&lt;/span&gt;,&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;string&#34;&gt;&amp;quot;pad_token&amp;quot;&lt;/span&gt;: &lt;span class=&#34;string&#34;&gt;&amp;quot;[PAD]&amp;quot;&lt;/span&gt;,&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;string&#34;&gt;&amp;quot;cls_token&amp;quot;&lt;/span&gt;: &lt;span class=&#34;string&#34;&gt;&amp;quot;[CLS]&amp;quot;&lt;/span&gt;,&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;string&#34;&gt;&amp;quot;mask_token&amp;quot;&lt;/span&gt;: &lt;span class=&#34;string&#34;&gt;&amp;quot;[MASK]&amp;quot;&lt;/span&gt;,&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;string&#34;&gt;&amp;quot;model_max_length&amp;quot;&lt;/span&gt;: max_length,&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;string&#34;&gt;&amp;quot;max_len&amp;quot;&lt;/span&gt;: max_length,&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    json.dump(tokenizer_cfg, f)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# tokenizer处理序列会自动添加CLS和SEP，但是tokenizer.tokenize()只会进行基础分词，不会添加特殊分词&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;tokenizer = BertTokenizerFast.from_pretrained(&lt;span class=&#34;string&#34;&gt;&amp;#x27;/data/hcfeng/learnLLM/TrainBert/small_pretrained-bert&amp;#x27;&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(&lt;span class=&#34;string&#34;&gt;f&amp;#x27;tokenier:&lt;span class=&#34;subst&#34;&gt;&amp;#123;tokenizer&amp;#125;&lt;/span&gt;&amp;#x27;&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;encode_with_truncation&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;examples&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;string&#34;&gt;&amp;quot;&amp;quot;&amp;quot; 使用词元分析对句子进行处理并截断的映射函数（Mapping function）&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;return&lt;/span&gt; tokenizer(examples[&lt;span class=&#34;string&#34;&gt;&amp;quot;text&amp;quot;&lt;/span&gt;], truncation=&lt;span class=&#34;literal&#34;&gt;True&lt;/span&gt;, padding=&lt;span class=&#34;string&#34;&gt;&amp;quot;max_length&amp;quot;&lt;/span&gt;,max_length=max_length, return_special_tokens_mask=&lt;span class=&#34;literal&#34;&gt;True&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;encode_without_truncation&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;examples&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;string&#34;&gt;&amp;quot;&amp;quot;&amp;quot; 使用词元分析对句子进行处理且不截断的映射函数（Mapping function）&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;return&lt;/span&gt; tokenizer(examples[&lt;span class=&#34;string&#34;&gt;&amp;quot;text&amp;quot;&lt;/span&gt;], return_special_tokens_mask=&lt;span class=&#34;literal&#34;&gt;True&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 编码函数将依赖于truncate_longer_samples变量&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;encode = encode_with_truncation &lt;span class=&#34;keyword&#34;&gt;if&lt;/span&gt; truncate_longer_samples &lt;span class=&#34;keyword&#34;&gt;else&lt;/span&gt; encode_without_truncation&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 对训练数据集进行分词处理&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;train_dataset = d[&lt;span class=&#34;string&#34;&gt;&amp;quot;train&amp;quot;&lt;/span&gt;].&lt;span class=&#34;built_in&#34;&gt;map&lt;/span&gt;(encode, batched=&lt;span class=&#34;literal&#34;&gt;True&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 对测试数据集进行分词处理&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;test_dataset = d[&lt;span class=&#34;string&#34;&gt;&amp;quot;test&amp;quot;&lt;/span&gt;].&lt;span class=&#34;built_in&#34;&gt;map&lt;/span&gt;(encode, batched=&lt;span class=&#34;literal&#34;&gt;True&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;if&lt;/span&gt; truncate_longer_samples:&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;comment&#34;&gt;# 移除其他列，将input_ids和attention_mask设置为PyTorch张量&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    train_dataset.set_format(&lt;span class=&#34;built_in&#34;&gt;type&lt;/span&gt;=&lt;span class=&#34;string&#34;&gt;&amp;quot;torch&amp;quot;&lt;/span&gt;, columns=[&lt;span class=&#34;string&#34;&gt;&amp;quot;input_ids&amp;quot;&lt;/span&gt;, &lt;span class=&#34;string&#34;&gt;&amp;quot;attention_mask&amp;quot;&lt;/span&gt;])&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    test_dataset.set_format(&lt;span class=&#34;built_in&#34;&gt;type&lt;/span&gt;=&lt;span class=&#34;string&#34;&gt;&amp;quot;torch&amp;quot;&lt;/span&gt;, columns=[&lt;span class=&#34;string&#34;&gt;&amp;quot;input_ids&amp;quot;&lt;/span&gt;, &lt;span class=&#34;string&#34;&gt;&amp;quot;attention_mask&amp;quot;&lt;/span&gt;])&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;else&lt;/span&gt;:&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;comment&#34;&gt;# 移除其他列，将它们保留为Python列表&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    test_dataset.set_format(columns=[&lt;span class=&#34;string&#34;&gt;&amp;quot;input_ids&amp;quot;&lt;/span&gt;, &lt;span class=&#34;string&#34;&gt;&amp;quot;attention_mask&amp;quot;&lt;/span&gt;, &lt;span class=&#34;string&#34;&gt;&amp;quot;special_tokens_mask&amp;quot;&lt;/span&gt;])&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    train_dataset.set_format(columns=[&lt;span class=&#34;string&#34;&gt;&amp;quot;input_ids&amp;quot;&lt;/span&gt;, &lt;span class=&#34;string&#34;&gt;&amp;quot;attention_mask&amp;quot;&lt;/span&gt;, &lt;span class=&#34;string&#34;&gt;&amp;quot;special_tokens_mask&amp;quot;&lt;/span&gt;])&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 用于不截断的情况&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;group_texts&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;examples&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;comment&#34;&gt;# 拼接所有文本&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    concatenated_examples = &amp;#123;k: &lt;span class=&#34;built_in&#34;&gt;list&lt;/span&gt;(chain(*examples[k])) &lt;span class=&#34;keyword&#34;&gt;for&lt;/span&gt; k &lt;span class=&#34;keyword&#34;&gt;in&lt;/span&gt; examples.keys()&amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    total_length = &lt;span class=&#34;built_in&#34;&gt;len&lt;/span&gt;(concatenated_examples[&lt;span class=&#34;built_in&#34;&gt;list&lt;/span&gt;(examples.keys())[&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;]])&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;comment&#34;&gt;# 舍弃了剩余部分，如果模型支持填充而不是舍弃，则可以根据需要自定义这部分&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;if&lt;/span&gt; total_length &amp;gt;= max_length:&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        total_length = (total_length // max_length) * max_length&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;comment&#34;&gt;# 按照最大长度分割成块&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    result = &amp;#123;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    k: [t[i : i + max_length] &lt;span class=&#34;keyword&#34;&gt;for&lt;/span&gt; i &lt;span class=&#34;keyword&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;built_in&#34;&gt;range&lt;/span&gt;(&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;, total_length, max_length)]&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;for&lt;/span&gt; k, t &lt;span class=&#34;keyword&#34;&gt;in&lt;/span&gt; concatenated_examples.items()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;return&lt;/span&gt; result&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;if&lt;/span&gt; &lt;span class=&#34;keyword&#34;&gt;not&lt;/span&gt; truncate_longer_samples:&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    train_dataset = train_dataset.&lt;span class=&#34;built_in&#34;&gt;map&lt;/span&gt;(group_texts, batched=&lt;span class=&#34;literal&#34;&gt;True&lt;/span&gt;,desc=&lt;span class=&#34;string&#34;&gt;f&amp;quot;Grouping texts in chunks of &lt;span class=&#34;subst&#34;&gt;&amp;#123;max_length&amp;#125;&lt;/span&gt;&amp;quot;&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    test_dataset = test_dataset.&lt;span class=&#34;built_in&#34;&gt;map&lt;/span&gt;(group_texts, batched=&lt;span class=&#34;literal&#34;&gt;True&lt;/span&gt;,desc=&lt;span class=&#34;string&#34;&gt;f&amp;quot;Grouping texts in chunks of &lt;span class=&#34;subst&#34;&gt;&amp;#123;max_length&amp;#125;&lt;/span&gt;&amp;quot;&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;comment&#34;&gt;# 将它们从列表转换为PyTorch张量&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    train_dataset.set_format(&lt;span class=&#34;string&#34;&gt;&amp;quot;torch&amp;quot;&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    test_dataset.set_format(&lt;span class=&#34;string&#34;&gt;&amp;quot;torch&amp;quot;&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 开始训练&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(&lt;span class=&#34;string&#34;&gt;f&amp;quot;tokenizer.vocab_size:&lt;span class=&#34;subst&#34;&gt;&amp;#123;tokenizer.vocab_size&amp;#125;&lt;/span&gt;&amp;quot;&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;#这里vocab_size一般设为tokenizer.vocab_size，其实只要大于这个数字都是可以的，只是会占用了显存空间（training)，但是不能设小，会出现索引越界的问题&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;model_config = BertConfig(vocab_size=tokenizer.vocab_size, max_position_embeddings=max_length) &lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;model = BertForMaskedLM(config=model_config)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;data_collator = DataCollatorForLanguageModeling(&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    tokenizer=tokenizer, mlm=&lt;span class=&#34;literal&#34;&gt;True&lt;/span&gt;, mlm_probability=&lt;span class=&#34;number&#34;&gt;0.2&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;training_args = TrainingArguments(&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    output_dir=model_path, &lt;span class=&#34;comment&#34;&gt;# 输出目录，用于保存模型检查点&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    eval_strategy=&lt;span class=&#34;string&#34;&gt;&amp;quot;steps&amp;quot;&lt;/span&gt;, &lt;span class=&#34;comment&#34;&gt;# 每隔`logging_steps`步进行一次评估&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    overwrite_output_dir=&lt;span class=&#34;literal&#34;&gt;True&lt;/span&gt;,&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    num_train_epochs=&lt;span class=&#34;number&#34;&gt;100&lt;/span&gt;, &lt;span class=&#34;comment&#34;&gt;# 训练时的轮数，可以根据需要进行调整&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    per_device_train_batch_size=&lt;span class=&#34;number&#34;&gt;10&lt;/span&gt;, &lt;span class=&#34;comment&#34;&gt;# 训练批量大小，可以根据GPU内存容量将其设置得尽可能大&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    gradient_accumulation_steps=&lt;span class=&#34;number&#34;&gt;8&lt;/span&gt;, &lt;span class=&#34;comment&#34;&gt;# 在更新权重之前累积梯度&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    per_device_eval_batch_size=&lt;span class=&#34;number&#34;&gt;64&lt;/span&gt;, &lt;span class=&#34;comment&#34;&gt;# 评估批量大小&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    logging_steps=&lt;span class=&#34;number&#34;&gt;1000&lt;/span&gt;, &lt;span class=&#34;comment&#34;&gt;# 每隔1000步进行一次评估，记录并保存模型检查点&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    save_steps=&lt;span class=&#34;number&#34;&gt;1000&lt;/span&gt;,&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;comment&#34;&gt;# load_best_model_at_end=True, # 是否在训练结束时加载最佳模型（根据损失）&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;comment&#34;&gt;# save_total_limit=3, # 如果磁盘空间有限，则可以限制只保存3个模型权重&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;trainer = Trainer(&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    model=model,&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    args=training_args,&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    data_collator=data_collator,&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    train_dataset=train_dataset,&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    eval_dataset=test_dataset,&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;#检查点&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(&lt;span class=&#34;string&#34;&gt;&amp;quot;input_ids dtype:&amp;quot;&lt;/span&gt;, train_dataset[&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;][&lt;span class=&#34;string&#34;&gt;&amp;quot;input_ids&amp;quot;&lt;/span&gt;].dtype)  &lt;span class=&#34;comment&#34;&gt;# 应该是 torch.int64 (long)&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(&lt;span class=&#34;string&#34;&gt;&amp;quot;attention_mask dtype:&amp;quot;&lt;/span&gt;, train_dataset[&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;][&lt;span class=&#34;string&#34;&gt;&amp;quot;attention_mask&amp;quot;&lt;/span&gt;].dtype)  &lt;span class=&#34;comment&#34;&gt;# 应该是 torch.int64 (long)&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;batch = data_collator([train_dataset[&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;], train_dataset[&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;]])&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(&lt;span class=&#34;string&#34;&gt;&amp;quot;input_ids shape:&amp;quot;&lt;/span&gt;, batch[&lt;span class=&#34;string&#34;&gt;&amp;quot;input_ids&amp;quot;&lt;/span&gt;].shape)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(&lt;span class=&#34;string&#34;&gt;f&amp;#x27;batch[&amp;quot;input_ids&amp;quot;]:&lt;span class=&#34;subst&#34;&gt;&amp;#123;batch[&lt;span class=&#34;string&#34;&gt;&amp;quot;input_ids&amp;quot;&lt;/span&gt;]&amp;#125;&lt;/span&gt;&amp;#x27;&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(&lt;span class=&#34;string&#34;&gt;&amp;quot;labels shape:&amp;quot;&lt;/span&gt;, batch[&lt;span class=&#34;string&#34;&gt;&amp;quot;labels&amp;quot;&lt;/span&gt;].shape)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# print(&amp;quot;labels min/max:&amp;quot;, torch.min(batch[&amp;quot;labels&amp;quot;]), torch.max(batch[&amp;quot;labels&amp;quot;]))&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(&lt;span class=&#34;string&#34;&gt;&amp;quot;input_ids min/max:&amp;quot;&lt;/span&gt;, torch.&lt;span class=&#34;built_in&#34;&gt;min&lt;/span&gt;(batch[&lt;span class=&#34;string&#34;&gt;&amp;quot;input_ids&amp;quot;&lt;/span&gt;]), torch.&lt;span class=&#34;built_in&#34;&gt;max&lt;/span&gt;(batch[&lt;span class=&#34;string&#34;&gt;&amp;quot;input_ids&amp;quot;&lt;/span&gt;]))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(torch.__version__)  &lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(torch.version.cuda)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(torch.cuda.is_available()) &lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 训练模型&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;trainer.train()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
</content>
        <category term="Bert" />
        <category term="GPT" />
        <updated>2025-05-16T16:37:02.000Z</updated>
    </entry>
    <entry>
        <id>http://example.com/2025/05/13/Transformer/</id>
        <title>Transformer</title>
        <link rel="alternate" href="http://example.com/2025/05/13/Transformer/"/>
        <content type="html">&lt;h2 id=&#34;transformer四层结构&#34;&gt;&lt;a class=&#34;markdownIt-Anchor&#34; href=&#34;#transformer四层结构&#34;&gt;#&lt;/a&gt; Transformer 四层结构&lt;/h2&gt;
&lt;p&gt;Transformer 结构：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;image1.png&#34; alt=&#34;image1&#34;&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;嵌入表示层&lt;/p&gt;
&lt;p&gt;Transformer 的自注意力机制是并行处理所有书如此，无法区分语序，所以需要进行位置编码，做法：先为每个单词生成向量嵌入表示，对每个单词所在位置对应一个位置向量，将两个向量进行相加。位置向量的生成公式如下：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;image2.png&#34; alt=&#34;image1&#34;&gt;&lt;/p&gt;
&lt;p&gt;根据位置的就选择正弦余弦函数进行计算，这个计算是对每个单词里面的向量的每一维都进行计算，代码如下所示：&lt;/p&gt;
&lt;figure class=&#34;highlight python&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;15&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;16&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;17&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;18&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;19&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;20&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;#transformer位置编码&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;class&lt;/span&gt; &lt;span class=&#34;title class_&#34;&gt;PositionalEncoder&lt;/span&gt;(nn.Module):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;__init__&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;self, d_model,max_seq_len = &lt;span class=&#34;number&#34;&gt;80&lt;/span&gt;&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;built_in&#34;&gt;super&lt;/span&gt;().__init__()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;variable language_&#34;&gt;self&lt;/span&gt;.d_model = d_model&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;     &lt;span class=&#34;comment&#34;&gt;# 根据pos和i创建一个常量PE矩阵&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        pe = torch.zeros(max_seq_len, d_model)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;keyword&#34;&gt;for&lt;/span&gt; pos &lt;span class=&#34;keyword&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;built_in&#34;&gt;range&lt;/span&gt;(max_seq_len):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            &lt;span class=&#34;keyword&#34;&gt;for&lt;/span&gt; i &lt;span class=&#34;keyword&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;built_in&#34;&gt;range&lt;/span&gt;(&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;, d_model, &lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;                pe[pos, i] = math.sin(pos / (&lt;span class=&#34;number&#34;&gt;10000&lt;/span&gt; ** (i/d_model)))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;                pe[pos, i + &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;] = math.cos(pos / (&lt;span class=&#34;number&#34;&gt;10000&lt;/span&gt; ** (i/d_model)))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        pe = pe.unsqueeze(&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;) &lt;span class=&#34;comment&#34;&gt;#形状 (1, seq_len, d_model)&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;variable language_&#34;&gt;self&lt;/span&gt;.register_buffer(&lt;span class=&#34;string&#34;&gt;&amp;#x27;pe&amp;#x27;&lt;/span&gt;, pe)   &lt;span class=&#34;comment&#34;&gt;#将 pe 保存为模型的一部分（不参与梯度更新，但会随模型保存/加载）&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;forward&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;self,x&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;comment&#34;&gt;#x:(batch_size, seq_len, d_model)&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        seq_len = x.size(&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        x = x + &lt;span class=&#34;variable language_&#34;&gt;self&lt;/span&gt;.pe[:,:seq_len].cuda()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;keyword&#34;&gt;return&lt;/span&gt; x&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;使用正余弦的原因是，函数的范围是 [-1，1] 与词向量相加不会太偏离原始语义，同时第 pos+k 个位置的编码是第 pos 个位置编码的线性组合（根据三角函数和角公式决定），这就蕴含了单词之间的距离信息：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;image3.png&#34; alt=&#34;image2&#34;&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;自注意力层&lt;/p&gt;
&lt;p&gt;自注意力机制，即自己作为 QKV 进行计算，但是解码器有两个注意力模块，一个是掩码多头，一个是交叉多头注意力，但是原理其实和下面代码差不多，直接用代码展示比较能说明：&lt;/p&gt;
&lt;figure class=&#34;highlight python&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;15&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;16&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;17&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;18&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;19&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;20&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;21&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;22&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;23&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;24&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;25&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;26&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;27&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;28&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;29&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;30&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;31&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;32&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;33&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;34&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;35&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;36&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;37&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;38&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;39&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;40&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;41&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;42&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;43&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;44&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;45&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;46&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;47&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;48&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;49&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;50&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;51&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;#transformer多头自注意力机制&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;class&lt;/span&gt; &lt;span class=&#34;title class_&#34;&gt;MultiHeadAttention&lt;/span&gt;(nn.Module):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;__init__&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;self, heads, d_model,dropout = &lt;span class=&#34;number&#34;&gt;0.1&lt;/span&gt;&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;built_in&#34;&gt;super&lt;/span&gt;().__init__()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;variable language_&#34;&gt;self&lt;/span&gt;.d_model = d_model&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;variable language_&#34;&gt;self&lt;/span&gt;.h = heads&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;variable language_&#34;&gt;self&lt;/span&gt;.d_k = d_model // heads&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;variable language_&#34;&gt;self&lt;/span&gt;.q_linear = nn.Linear(d_model,d_model)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;variable language_&#34;&gt;self&lt;/span&gt;.k_linear = nn.Linear(d_model,d_model)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;variable language_&#34;&gt;self&lt;/span&gt;.v_linear = nn.Linear(d_model,d_model)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;variable language_&#34;&gt;self&lt;/span&gt;.dropout = nn.Dropout(dropout)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;variable language_&#34;&gt;self&lt;/span&gt;.out = nn.Linear(d_model,d_model)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;attention&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;q, k, v, d_k, mask = &lt;span class=&#34;literal&#34;&gt;None&lt;/span&gt;, dropout = &lt;span class=&#34;literal&#34;&gt;None&lt;/span&gt; &lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;comment&#34;&gt;# 转置k相乘 ​​除以 math.sqrt(d_k)​​ 的操作是缩放点积注意力，防止点积数值过大​&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        scores = torch.matmul(q,k.transpose(-&lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;,-&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;)) / math.sqrt(d_k)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;keyword&#34;&gt;if&lt;/span&gt; mask &lt;span class=&#34;keyword&#34;&gt;is&lt;/span&gt; &lt;span class=&#34;keyword&#34;&gt;not&lt;/span&gt; &lt;span class=&#34;literal&#34;&gt;None&lt;/span&gt;:&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            mask = mask.unsqueeze(&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            scores = scores.masked_fill(mask == &lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;, -&lt;span class=&#34;number&#34;&gt;1e9&lt;/span&gt;) &lt;span class=&#34;comment&#34;&gt;#掩盖那些为了补全长度而增加的单元，使其通过Softmax计算后为0&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        scores = F.sofmax(scores,dim=-&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;keyword&#34;&gt;if&lt;/span&gt; dropout &lt;span class=&#34;keyword&#34;&gt;is&lt;/span&gt; &lt;span class=&#34;keyword&#34;&gt;not&lt;/span&gt; &lt;span class=&#34;literal&#34;&gt;None&lt;/span&gt;:&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            scores = dropout(scores)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        output = torch.matmul(scores,v)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;keyword&#34;&gt;return&lt;/span&gt; output&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;forward&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;self, q, k, v, mask = &lt;span class=&#34;literal&#34;&gt;None&lt;/span&gt;&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        batch_size = q.size(&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;comment&#34;&gt;# 利用线性计算划分成h个头&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        q = &lt;span class=&#34;variable language_&#34;&gt;self&lt;/span&gt;.q_linear(q).view(batch_size,-&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;,&lt;span class=&#34;variable language_&#34;&gt;self&lt;/span&gt;.h,&lt;span class=&#34;variable language_&#34;&gt;self&lt;/span&gt;.d_k)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        k = &lt;span class=&#34;variable language_&#34;&gt;self&lt;/span&gt;.k_linear(k).view(batch_size,-&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;,&lt;span class=&#34;variable language_&#34;&gt;self&lt;/span&gt;.h,&lt;span class=&#34;variable language_&#34;&gt;self&lt;/span&gt;.d_k)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        v = &lt;span class=&#34;variable language_&#34;&gt;self&lt;/span&gt;.v_linear(v).view(batch_size,-&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;,&lt;span class=&#34;variable language_&#34;&gt;self&lt;/span&gt;.h,&lt;span class=&#34;variable language_&#34;&gt;self&lt;/span&gt;.d_k)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;comment&#34;&gt;#转置头和seq_len位置&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        k = k.transpose(&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;,&lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        q = q.transpose(&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;,&lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        v = v.transpose(&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;,&lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        scores = &lt;span class=&#34;variable language_&#34;&gt;self&lt;/span&gt;.attention(q, k, v, &lt;span class=&#34;variable language_&#34;&gt;self&lt;/span&gt;.d_k, mask, &lt;span class=&#34;variable language_&#34;&gt;self&lt;/span&gt;.dropout)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;comment&#34;&gt;# 拼接多头输出并线性变换&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        concat = scores.transpose(&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;).contiguous().view(batch_size, -&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;, &lt;span class=&#34;variable language_&#34;&gt;self&lt;/span&gt;.d_model)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        output = &lt;span class=&#34;variable language_&#34;&gt;self&lt;/span&gt;.out(concat) &lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;keyword&#34;&gt;return&lt;/span&gt; output&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;前馈层&lt;/p&gt;
&lt;p&gt;接收注意力层的输出，通过带有 ReLU 的 2 层全连接网络，第一层会映射到高纬度，因为隐藏层维度的增大有利于提高质量（实验证明）：&lt;/p&gt;
&lt;figure class=&#34;highlight python&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;14&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;#前馈层&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;class&lt;/span&gt; &lt;span class=&#34;title class_&#34;&gt;FeedForward&lt;/span&gt;(nn.Module):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;__init__&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;self, d_model, d_ff = &lt;span class=&#34;number&#34;&gt;2038&lt;/span&gt;, dropout = &lt;span class=&#34;number&#34;&gt;0.1&lt;/span&gt;&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;built_in&#34;&gt;super&lt;/span&gt;().__init__()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;variable language_&#34;&gt;self&lt;/span&gt;.linear1 = nn.Linear(d_model, d_ff)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;variable language_&#34;&gt;self&lt;/span&gt;.dropout = nn.Dropout(dropout)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;variable language_&#34;&gt;self&lt;/span&gt;.linear2 = nn.Linear(d_ff,d_model)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;forward&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;self, x&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        x = &lt;span class=&#34;variable language_&#34;&gt;self&lt;/span&gt;.dropout(F.relu(&lt;span class=&#34;variable language_&#34;&gt;self&lt;/span&gt;.linear1(x)))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        x = &lt;span class=&#34;variable language_&#34;&gt;self&lt;/span&gt;.linear2(x)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;keyword&#34;&gt;return&lt;/span&gt; x&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;残差连接和归一化&lt;/p&gt;
&lt;p&gt;​	由 Transformer 结构组成的网络结构通常都非常庞大。编码器和解码器均由很多层基本的 Transformer 块组成，每一层中都包含复杂的非线性映射，这就导致模型的训练比较困难。因此，研究人员在 Transformer 块中进一步引入了残差连接与层归一化技术，以进一步提升训练的稳定性。具体来说，残差连接主要是指使用一条直连通道直接将对应子层的输入连接到输出，避免在优化过程中因网络过深而产生潜在的梯度消失问题。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;解码器与编码器&#34;&gt;&lt;a class=&#34;markdownIt-Anchor&#34; href=&#34;#解码器与编码器&#34;&gt;#&lt;/a&gt; 解码器与编码器&lt;/h2&gt;
&lt;p&gt;​	编码器端较容易实现。相比于编码器端，解码器端更复杂。具体来说，解码器的每个 Transformer 块的第一个自注意力子层额外增加了注意力掩码，对应图中的掩码多头注意力部分。这主要是因为在翻译的过程中，编码器端主要用于编码源语言序列的信息，而这个序列是完全已知的，因而编码器仅需要考虑如何融合上下文语义信息。解码器端则负责生成目标语言序列，这一生成过程是自回归的，即对于每一个单词的生成过程，仅有当前单词之前的目标语言序列是可以被观测的，因此这一额外增加的掩码是用来掩盖后续的文本信息的，以防模型在训练阶段直接看到后续的文本序列，进而无法得到有效的训练。此外，解码器端额外增加了一个多头交叉注意力模块，使用交叉注意力方法，同时接收来自编码器端的输出和当前 Transformer 块的前一个掩码注意力层的输出。查询是通过解码器前一层的输出进行投影的，而键和值是使用编码器的输出进行投影的。&lt;/p&gt;
&lt;p&gt;​	解码器端以自回归的方式生成目标语言文本，即在每个时间步 &lt;em&gt;t&lt;/em&gt;，根据编码器端输出的源语言文本表示，以及前 t &lt;em&gt;−&lt;/em&gt; 1 个时刻生成的目标语言文本，生成当前时刻的目标语言单词（以我的理解来说，训练阶段是没有显示时间步概念的，通过&lt;strong&gt;一次性输入完整序列 + 掩码矩阵&lt;/strong&gt;，在单次前向传播中并行计算出所有位置的输出，同时利用掩码强制模型行为与自回归一致，而推理时必须显式按时间步生成，因为未来词未知（无法并行））。&lt;/p&gt;
&lt;h2 id=&#34;以推理生成中文翻译-我爱你-为例&#34;&gt;&lt;a class=&#34;markdownIt-Anchor&#34; href=&#34;#以推理生成中文翻译-我爱你-为例&#34;&gt;#&lt;/a&gt; 以推理生成中文翻译  &lt;code&gt;&amp;quot;我爱你&amp;quot;&lt;/code&gt;  为例：&lt;/h2&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:center&#34;&gt;时间步&lt;/th&gt;
&lt;th style=&#34;text-align:center&#34;&gt;图 1 中对应的模块流程&lt;/th&gt;
&lt;th style=&#34;text-align:center&#34;&gt;具体操作&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;&lt;code&gt;t=1&lt;/code&gt;&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;词元嵌入 → 位置编码 → 掩码多头注意力 → 编码器 - 解码器注意力 → 前馈网络 → Softmax&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;输入  &lt;code&gt;&amp;lt;start&amp;gt;&lt;/code&gt; ，输出  &lt;code&gt;&amp;quot;我&amp;quot;&lt;/code&gt;  的概率分布。&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;&lt;code&gt;t=2&lt;/code&gt;&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;词元嵌入 ( &lt;code&gt;&amp;lt;start&amp;gt; 我&lt;/code&gt; ) → 位置编码 → 掩码多头注意力 → … → Softmax&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;输入  &lt;code&gt;&amp;lt;start&amp;gt; 我&lt;/code&gt; ，输出  &lt;code&gt;&amp;quot;爱&amp;quot;&lt;/code&gt;  的概率分布。&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;&lt;code&gt;t=3&lt;/code&gt;&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;词元嵌入 ( &lt;code&gt;&amp;lt;start&amp;gt; 我爱&lt;/code&gt; ) → 位置编码 → … → Softmax&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;输入  &lt;code&gt;&amp;lt;start&amp;gt; 我爱&lt;/code&gt; ，输出  &lt;code&gt;&amp;quot;你&amp;quot;&lt;/code&gt;  的概率分布。&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;&lt;code&gt;t=4&lt;/code&gt;&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;词元嵌入 ( &lt;code&gt;&amp;lt;start&amp;gt; 我爱你&lt;/code&gt; ) → … → Softmax&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;输入  &lt;code&gt;&amp;lt;start&amp;gt; 我爱你&lt;/code&gt; ，输出  &lt;code&gt;&amp;lt;end&amp;gt;&lt;/code&gt;  的概率分布，终止生成。&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;可参考文章：&lt;a href=&#34;https://blog.csdn.net/m0_64148253/article/details/140422497&#34;&gt;https://blog.csdn.net/m0_64148253/article/details/140422497&lt;/a&gt;&lt;/p&gt;
</content>
        <category term="LLM" />
        <category term="transformer" />
        <updated>2025-05-13T07:07:29.000Z</updated>
    </entry>
    <entry>
        <id>http://example.com/2025/05/12/LLM-concept/</id>
        <title>LLM-concept</title>
        <link rel="alternate" href="http://example.com/2025/05/12/LLM-concept/"/>
        <content type="html">&lt;h1 id=&#34;大模型基本概念&#34;&gt;&lt;a class=&#34;markdownIt-Anchor&#34; href=&#34;#大模型基本概念&#34;&gt;#&lt;/a&gt; 大模型基本概念&lt;/h1&gt;
&lt;h2 id=&#34;目标&#34;&gt;&lt;a class=&#34;markdownIt-Anchor&#34; href=&#34;#目标&#34;&gt;#&lt;/a&gt; 目标&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;语言模型就是对自然语言的概率分布进行建模，即 P (w1 w2 w3 … wn)，计算这些词构成的这句话成为合法的一句话的概率&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;计算下一个词的概率 P (wn | w1 w2 w3… wn-1)&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;image1.png&#34; alt=&#34;image&#34;&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;发展历程&#34;&gt;&lt;a class=&#34;markdownIt-Anchor&#34; href=&#34;#发展历程&#34;&gt;#&lt;/a&gt; 发展历程&lt;/h2&gt;
&lt;p&gt;从 n-gram:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;image2.png&#34; alt=&#34;image&#34;&gt;&lt;/p&gt;
&lt;p&gt;到 neural language model: 每个词都映射成一个低维向量&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;image3.png&#34; alt=&#34;image&#34;&gt;&lt;/p&gt;
&lt;p&gt;再到后面的 transformer 出现，transformer 的出现，NLP 进入了预训练微调阶段，也就是只需把预训练好的模型用特定任务的训练集去微调（fine-tune），即可对下游任务进行操作，这种模型是 PLM。&lt;/p&gt;
&lt;p&gt;随着 OpenAI 发布的 1750 亿个参数（GPT-3），开启 LLM 时代&lt;/p&gt;
&lt;h2 id=&#34;问题发现&#34;&gt;&lt;a class=&#34;markdownIt-Anchor&#34; href=&#34;#问题发现&#34;&gt;#&lt;/a&gt; 问题发现&lt;/h2&gt;
&lt;p&gt;・大模型（如 GPT-3）参数量极大（1750 亿 +），传统 “预训练 + 微调” 范式成本过高（需为每个任务调整海量参数）。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;解决方案：&lt;br&gt;
・开发新范式（ICL/Prompt），通过输入指令或示例直接引导模型，避免微调。&lt;/p&gt;
&lt;p&gt;・但要让模型支持这种范式，必须在预训练阶段就赋予它相关能力（如理解指令、模仿示例）。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;模型构建的关键：&lt;br&gt;
・预训练阶段：用海量多样化数据（图书、网页、指令数据等）训练模型，使其隐式掌握 ICL/Prompt 所需的能力（如任务模式识别、指令遵循）。&lt;/p&gt;
&lt;p&gt;・后续阶段（SFT+RLHF）：进一步优化模型对新范式的响应质量（如更精准的指令理解、更安全的输出）。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;结论：&lt;br&gt;
・新范式（ICL/Prompt）依赖特定训练的模型：只有通过大规模预训练（及后续优化）的模型，才能直接通过上下文或指令适配任务，而传统小模型无法做到这一点。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;llm的构建流程&#34;&gt;&lt;a class=&#34;markdownIt-Anchor&#34; href=&#34;#llm的构建流程&#34;&gt;#&lt;/a&gt; LLM 的构建流程&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;预训练： 利用海量训练数据构建多样化内容，构建基础模型 ——&amp;gt; 对长文本建模，使模型具有语言生成能力&lt;/li&gt;
&lt;li&gt;有监督微调 SFT：用少量高质量数据集，通过有监督训练使模型具有问答、写作的能力，数据包括：用户输入提示词和对应理想输出结果&lt;/li&gt;
&lt;li&gt;奖励建模 RM：训练一个能够判断文本质量的裁判，对同个提示词，比较 SFT 生成的多个输出的质量&lt;/li&gt;
&lt;li&gt;强化学习 RLHF (human feedback)：基于 RM，优化 SFT 模型&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;SFT 相当于学生学会答题，RM 是评分老师，判断 answer 好坏，RLHF 是学生根据老师评分改进答题策略&lt;/p&gt;
&lt;h2 id=&#34;补充&#34;&gt;&lt;a class=&#34;markdownIt-Anchor&#34; href=&#34;#补充&#34;&gt;#&lt;/a&gt; 补充&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;N-gram 模型详解&lt;/strong&gt;&lt;br&gt;
 N-gram 是一种基于统计的语言模型，用于预测或生成文本中的下一个词，其核心思想是：一个词的出现概率依赖于它前面的有限个词（n-1 个词）。它是自然语言处理（NLP）中最基础且广泛使用的模型之一。&lt;/p&gt;
&lt;p&gt;N-gram 的定义：&lt;/p&gt;
&lt;p&gt;・指文本中连续的 &lt;em&gt;n&lt;/em&gt; 个词（或字符）组成的序列。&lt;/p&gt;
&lt;p&gt;・例如：&lt;/p&gt;
&lt;figure class=&#34;highlight plaintext&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;◦ Unigram (1-gram): &amp;quot;the&amp;quot;、&amp;quot;cat&amp;quot;、&amp;quot;sat&amp;quot;（单个词）。  &lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;◦ Bigram (2-gram): &amp;quot;the cat&amp;quot;、&amp;quot;cat sat&amp;quot;、&amp;quot;sat on&amp;quot;（两个连续词）。  &lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;◦ Trigram (3-gram): &amp;quot;the cat sat&amp;quot;、&amp;quot;cat sat on&amp;quot;（三个连续词）。  &lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;・核心假设：&lt;/p&gt;
&lt;p&gt;・马尔可夫假设：当前词的概率仅依赖于前 &lt;em&gt;n-1&lt;/em&gt; 个词，而非整个历史。&lt;/p&gt;
&lt;figure class=&#34;highlight plaintext&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;◦ 例如，Bigram 模型认为 `P(sat | the cat)` ≈ `P(sat | cat)`，忽略更早的上下文。&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;hr&gt;
&lt;p&gt;&lt;strong&gt;如何计算概率？&lt;/strong&gt;&lt;br&gt;
N-gram 通过统计语料库中词序列的频率来估计概率：&lt;/p&gt;
&lt;p&gt;计算  &lt;code&gt;P(sat | the cat)&lt;/code&gt; ：&lt;/p&gt;
&lt;p&gt;P(sat∣the cat)=Count(“the cat”)Count(“the cat sat”)&lt;/p&gt;
&lt;p&gt;若语料中 “the cat” 出现 100 次，“the cat sat” 出现 30 次，则  &lt;code&gt;P(sat | the cat) = 0.3&lt;/code&gt; 。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;N-gram 的优缺点&lt;/strong&gt;&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;优点&lt;/th&gt;
&lt;th&gt;缺点&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;简单高效，计算速度快。&lt;/td&gt;
&lt;td&gt;无法捕捉长距离依赖（如 “The cat… sat” 相隔较远时）。&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;小规模数据即可训练。&lt;/td&gt;
&lt;td&gt;数据稀疏性（罕见 n-gram 概率不准确）。&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;曾广泛用于机器翻译、拼写检查等任务。&lt;/td&gt;
&lt;td&gt;无法理解语义（仅统计共现频率）。&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
</content>
        <category term="LLM" />
        <category term="concept" />
        <updated>2025-05-12T07:54:00.000Z</updated>
    </entry>
</feed>
