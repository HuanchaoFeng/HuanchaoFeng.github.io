<?xml version="1.0"?>
<rss version="2.0">
    <channel>
        <title>Phoenix • Posts by &#34;gpt&#34; tag</title>
        <link>http://example.com</link>
        <description>Every day is a chance to learn something new</description>
        <language>en</language>
        <pubDate>Sat, 17 May 2025 00:37:02 +0800</pubDate>
        <lastBuildDate>Sat, 17 May 2025 00:37:02 +0800</lastBuildDate>
        <category>datalinkx</category>
        <category>混合专家模型</category>
        <category>LLaMA</category>
        <category>LLM</category>
        <category>concept</category>
        <category>Bert</category>
        <category>GPT</category>
        <category>transformer</category>
        <category>resume</category>
        <category>report_export</category>
        <item>
            <guid isPermalink="true">http://example.com/2025/05/17/GPT-BertBuild/</guid>
            <title>GPT&amp;BertBuild</title>
            <link>http://example.com/2025/05/17/GPT-BertBuild/</link>
            <category>Bert</category>
            <category>GPT</category>
            <pubDate>Sat, 17 May 2025 00:37:02 +0800</pubDate>
            <description><![CDATA[ &lt;h2 id=&#34;生成式预训练语言模型gpt&#34;&gt;&lt;a class=&#34;markdownIt-Anchor&#34; href=&#34;#生成式预训练语言模型gpt&#34;&gt;#&lt;/a&gt; 生成式预训练语言模型 GPT&lt;/h2&gt;
&lt;p&gt;GPT 的模型结构，由多个 transformer 的 decoder 组成，结构如下：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;image1.png&#34; alt=&#34;image1&#34;&gt;&lt;/p&gt;
&lt;p&gt;该模型利用的是 transformer 的解码器部分，训练和推理的过程是类似的，12 层 transformer 模块都在做类似的事情，到最后一层后输出预测的分数（映射到词分类中，得到预测的分数 / 置信度）&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;有监督下游任务微调：&lt;/p&gt;
&lt;p&gt;在进行下游任务微调时，仅使用 GPT 的最后一层的最后一个词的隐藏状态，同个全连接层映射到标签空间。因为每个词的隐藏状态都聚合了左侧所有历史词的信息，因此最后一个词的隐藏状态天然编码了整个序列的全局语义。&lt;/p&gt;
&lt;p&gt;同时再进行微调的时候，可能会出现模型遗忘预训练阶段学习的通用只是表示，损失通用与泛化能力，出现灾难性遗忘的问题，所以通常采用混合预训练任务损失和下游微调损失缓解这一问题，Loss Function 如下:&lt;br&gt;
&lt;img src=&#34;image2.png&#34; alt=&#34;image2&#34;&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;bert模型构建&#34;&gt;&lt;a class=&#34;markdownIt-Anchor&#34; href=&#34;#bert模型构建&#34;&gt;#&lt;/a&gt; Bert 模型构建&lt;/h2&gt;
&lt;p&gt;Bert 模型一般是基于 Transformer 的编码器部分构建的，是一个相当于完形填空 (mask) 的模型，是考虑双向的模型（同时利用两侧信息）&lt;/p&gt;
&lt;p&gt;例子：&lt;/p&gt;
&lt;figure class=&#34;highlight python&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;15&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;16&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;17&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;18&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;19&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;input&lt;/span&gt;:the cat site on the mat&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;tokenizer(分词):（假设不加入CLS标记和SEP标记）&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    code:[&lt;span class=&#34;number&#34;&gt;1996&lt;/span&gt;,&lt;span class=&#34;number&#34;&gt;4248&lt;/span&gt;,&lt;span class=&#34;number&#34;&gt;2825&lt;/span&gt;,&lt;span class=&#34;number&#34;&gt;2007&lt;/span&gt;,&lt;span class=&#34;number&#34;&gt;1996&lt;/span&gt;,&lt;span class=&#34;number&#34;&gt;3829&lt;/span&gt;,&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;,&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;] &lt;span class=&#34;comment&#34;&gt;# 0为pad的编码，max假设为8&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    attention_mask:[&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;,&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;,&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;,&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;,&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;,&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;,&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;] &lt;span class=&#34;comment&#34;&gt;# 0表示填充的位置&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;random mask:选取到了site作为掩码，替换为mask的编码-&amp;gt;&lt;span class=&#34;number&#34;&gt;103&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;	code:[&lt;span class=&#34;number&#34;&gt;1996&lt;/span&gt;,&lt;span class=&#34;number&#34;&gt;4248&lt;/span&gt;,&lt;span class=&#34;number&#34;&gt;103&lt;/span&gt;,&lt;span class=&#34;number&#34;&gt;2007&lt;/span&gt;,&lt;span class=&#34;number&#34;&gt;1996&lt;/span&gt;,&lt;span class=&#34;number&#34;&gt;3829&lt;/span&gt;,&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;,&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;]&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    attention_mask:[&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;,&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;,&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;,&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;,&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;,&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;,&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;,&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;]&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    label:[-&lt;span class=&#34;number&#34;&gt;100&lt;/span&gt;,-&lt;span class=&#34;number&#34;&gt;100&lt;/span&gt;,&lt;span class=&#34;number&#34;&gt;2825&lt;/span&gt;,-&lt;span class=&#34;number&#34;&gt;100&lt;/span&gt;,-&lt;span class=&#34;number&#34;&gt;100&lt;/span&gt;,-&lt;span class=&#34;number&#34;&gt;100&lt;/span&gt;,-&lt;span class=&#34;number&#34;&gt;100&lt;/span&gt;,-&lt;span class=&#34;number&#34;&gt;100&lt;/span&gt;] &lt;span class=&#34;comment&#34;&gt;#这个是用于计算掩码的真实标签，-100表示不需要计算，只保留被掩码的位置&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;train:&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    将上述数据送入Bert模型中&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;output:&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    [&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        [..,..,..,..,],&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        [..,..,..,..,],&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        [..,..,..,..,], &lt;span class=&#34;comment&#34;&gt;#取第二个位置进行计算交叉熵&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        [..,..,..,..,],&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        ........&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    ]&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;训练过程：加载 dataset, 切分 traindataset 和 testdataset --&amp;gt; 用 traindataset 训练词元分析器，形成 vocab 词表 --&amp;gt; 加载预训练词元分析器 --&amp;gt; 分词序列 --&amp;gt; 加载随即权重的 BERT 模型，设置掩码比例，进行训练，下面是代码训练过程：&lt;/p&gt;
&lt;p&gt;dataset 获取与镜像设置：&lt;/p&gt;
&lt;figure class=&#34;highlight python&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;#下载数据集：&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;pip install huggingface_hub&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;huggingface-cli download --repo-&lt;span class=&#34;built_in&#34;&gt;type&lt;/span&gt; dataset legacy-datasets/wikipedia  --local-&lt;span class=&#34;built_in&#34;&gt;dir&lt;/span&gt; wikipedia&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# mirror&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;export HF_ENDPOINT=https://hf-mirror.com&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;environment (有部分可能不需要）:&lt;/p&gt;
&lt;figure class=&#34;highlight python&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;15&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;16&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;17&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;18&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;19&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;20&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;21&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;22&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;23&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;24&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;25&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;26&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;27&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;28&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;29&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;30&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;31&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;32&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;33&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;34&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;35&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;36&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;37&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;38&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;39&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;40&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;41&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;42&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;43&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;44&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;45&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;46&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;47&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;48&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;49&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;50&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;51&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;52&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;53&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;54&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;55&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;56&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;57&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;58&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;59&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;60&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;61&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;62&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;63&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;64&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;65&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;66&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;67&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;68&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;69&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;70&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;71&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;72&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;73&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;74&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;75&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;76&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;77&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;78&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;79&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;80&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;81&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;82&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;83&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;84&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;85&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;86&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;channels:&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;  - defaults&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;dependencies:&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;  - _libgcc_mutex=&lt;span class=&#34;number&#34;&gt;0.1&lt;/span&gt;=main&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;  - _openmp_mutex=&lt;span class=&#34;number&#34;&gt;5.1&lt;/span&gt;=1_gnu&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;  - bzip2=&lt;span class=&#34;number&#34;&gt;1.0&lt;/span&gt;&lt;span class=&#34;number&#34;&gt;.8&lt;/span&gt;=h5eee18b_6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;  - ca-certificates=&lt;span class=&#34;number&#34;&gt;2025.2&lt;/span&gt;&lt;span class=&#34;number&#34;&gt;.25&lt;/span&gt;=h06a4308_0&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;  - expat=&lt;span class=&#34;number&#34;&gt;2.7&lt;/span&gt;&lt;span class=&#34;number&#34;&gt;.1&lt;/span&gt;=h6a678d5_0&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;  - ld_impl_linux-&lt;span class=&#34;number&#34;&gt;64&lt;/span&gt;=&lt;span class=&#34;number&#34;&gt;2.40&lt;/span&gt;=h12ee557_0&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;  - libffi=&lt;span class=&#34;number&#34;&gt;3.4&lt;/span&gt;&lt;span class=&#34;number&#34;&gt;.4&lt;/span&gt;=h6a678d5_1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;  - libgcc-ng=&lt;span class=&#34;number&#34;&gt;11.2&lt;/span&gt;&lt;span class=&#34;number&#34;&gt;.0&lt;/span&gt;=h1234567_1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;  - libgomp=&lt;span class=&#34;number&#34;&gt;11.2&lt;/span&gt;&lt;span class=&#34;number&#34;&gt;.0&lt;/span&gt;=h1234567_1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;  - libstdcxx-ng=&lt;span class=&#34;number&#34;&gt;11.2&lt;/span&gt;&lt;span class=&#34;number&#34;&gt;.0&lt;/span&gt;=h1234567_1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;  - libuuid=&lt;span class=&#34;number&#34;&gt;1.41&lt;/span&gt;&lt;span class=&#34;number&#34;&gt;.5&lt;/span&gt;=h5eee18b_0&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;  - ncurses=&lt;span class=&#34;number&#34;&gt;6.4&lt;/span&gt;=h6a678d5_0&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;  - openssl=&lt;span class=&#34;number&#34;&gt;3.0&lt;/span&gt;&lt;span class=&#34;number&#34;&gt;.16&lt;/span&gt;=h5eee18b_0&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;  - pip=&lt;span class=&#34;number&#34;&gt;25.1&lt;/span&gt;=pyhc872135_2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;  - python=&lt;span class=&#34;number&#34;&gt;3.12&lt;/span&gt;&lt;span class=&#34;number&#34;&gt;.9&lt;/span&gt;=h5148396_0&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;  - readline=&lt;span class=&#34;number&#34;&gt;8.2&lt;/span&gt;=h5eee18b_0&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;  - setuptools=&lt;span class=&#34;number&#34;&gt;78.1&lt;/span&gt;&lt;span class=&#34;number&#34;&gt;.1&lt;/span&gt;=py312h06a4308_0&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;  - sqlite=&lt;span class=&#34;number&#34;&gt;3.45&lt;/span&gt;&lt;span class=&#34;number&#34;&gt;.3&lt;/span&gt;=h5eee18b_0&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;  - tk=&lt;span class=&#34;number&#34;&gt;8.6&lt;/span&gt;&lt;span class=&#34;number&#34;&gt;.14&lt;/span&gt;=h39e8969_0&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;  - wheel=&lt;span class=&#34;number&#34;&gt;0.45&lt;/span&gt;&lt;span class=&#34;number&#34;&gt;.1&lt;/span&gt;=py312h06a4308_0&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;  - xz=&lt;span class=&#34;number&#34;&gt;5.6&lt;/span&gt;&lt;span class=&#34;number&#34;&gt;.4&lt;/span&gt;=h5eee18b_1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;  - zlib=&lt;span class=&#34;number&#34;&gt;1.2&lt;/span&gt;&lt;span class=&#34;number&#34;&gt;.13&lt;/span&gt;=h5eee18b_1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;  - pip:&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;      - accelerate==&lt;span class=&#34;number&#34;&gt;0.26&lt;/span&gt;&lt;span class=&#34;number&#34;&gt;.0&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;      - aiohappyeyeballs==&lt;span class=&#34;number&#34;&gt;2.6&lt;/span&gt;&lt;span class=&#34;number&#34;&gt;.1&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;      - aiohttp==&lt;span class=&#34;number&#34;&gt;3.11&lt;/span&gt;&lt;span class=&#34;number&#34;&gt;.18&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;      - aiosignal==&lt;span class=&#34;number&#34;&gt;1.3&lt;/span&gt;&lt;span class=&#34;number&#34;&gt;.2&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;      - attrs==&lt;span class=&#34;number&#34;&gt;25.3&lt;/span&gt;&lt;span class=&#34;number&#34;&gt;.0&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;      - certifi==&lt;span class=&#34;number&#34;&gt;2025.4&lt;/span&gt;&lt;span class=&#34;number&#34;&gt;.26&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;      - charset-normalizer==&lt;span class=&#34;number&#34;&gt;3.4&lt;/span&gt;&lt;span class=&#34;number&#34;&gt;.2&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;      - datasets==&lt;span class=&#34;number&#34;&gt;3.6&lt;/span&gt;&lt;span class=&#34;number&#34;&gt;.0&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;      - dill==&lt;span class=&#34;number&#34;&gt;0.3&lt;/span&gt;&lt;span class=&#34;number&#34;&gt;.8&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;      - filelock==&lt;span class=&#34;number&#34;&gt;3.18&lt;/span&gt;&lt;span class=&#34;number&#34;&gt;.0&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;      - frozenlist==&lt;span class=&#34;number&#34;&gt;1.6&lt;/span&gt;&lt;span class=&#34;number&#34;&gt;.0&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;      - fsspec==&lt;span class=&#34;number&#34;&gt;2025.3&lt;/span&gt;&lt;span class=&#34;number&#34;&gt;.0&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;      - huggingface-hub==&lt;span class=&#34;number&#34;&gt;0.31&lt;/span&gt;&lt;span class=&#34;number&#34;&gt;.2&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;      - idna==&lt;span class=&#34;number&#34;&gt;3.10&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;      - jinja2==&lt;span class=&#34;number&#34;&gt;3.1&lt;/span&gt;&lt;span class=&#34;number&#34;&gt;.6&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;      - markupsafe==&lt;span class=&#34;number&#34;&gt;3.0&lt;/span&gt;&lt;span class=&#34;number&#34;&gt;.2&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;      - mpmath==&lt;span class=&#34;number&#34;&gt;1.3&lt;/span&gt;&lt;span class=&#34;number&#34;&gt;.0&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;      - multidict==&lt;span class=&#34;number&#34;&gt;6.4&lt;/span&gt;&lt;span class=&#34;number&#34;&gt;.3&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;      - multiprocess==&lt;span class=&#34;number&#34;&gt;0.70&lt;/span&gt;&lt;span class=&#34;number&#34;&gt;.16&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;      - mwparserfromhell==&lt;span class=&#34;number&#34;&gt;0.6&lt;/span&gt;&lt;span class=&#34;number&#34;&gt;.6&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;      - networkx==&lt;span class=&#34;number&#34;&gt;3.4&lt;/span&gt;&lt;span class=&#34;number&#34;&gt;.2&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;      - numpy==&lt;span class=&#34;number&#34;&gt;2.2&lt;/span&gt;&lt;span class=&#34;number&#34;&gt;.5&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;      - nvidia-cublas-cu12==&lt;span class=&#34;number&#34;&gt;12.6&lt;/span&gt;&lt;span class=&#34;number&#34;&gt;.4&lt;/span&gt;&lt;span class=&#34;number&#34;&gt;.1&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;      - nvidia-cuda-cupti-cu12==&lt;span class=&#34;number&#34;&gt;12.6&lt;/span&gt;&lt;span class=&#34;number&#34;&gt;.80&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;      - nvidia-cuda-nvrtc-cu12==&lt;span class=&#34;number&#34;&gt;12.6&lt;/span&gt;&lt;span class=&#34;number&#34;&gt;.77&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;      - nvidia-cuda-runtime-cu12==&lt;span class=&#34;number&#34;&gt;12.6&lt;/span&gt;&lt;span class=&#34;number&#34;&gt;.77&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;      - nvidia-cudnn-cu12==&lt;span class=&#34;number&#34;&gt;9.5&lt;/span&gt;&lt;span class=&#34;number&#34;&gt;.1&lt;/span&gt;&lt;span class=&#34;number&#34;&gt;.17&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;      - nvidia-cufft-cu12==&lt;span class=&#34;number&#34;&gt;11.3&lt;/span&gt;&lt;span class=&#34;number&#34;&gt;.0&lt;/span&gt;&lt;span class=&#34;number&#34;&gt;.4&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;      - nvidia-cufile-cu12==&lt;span class=&#34;number&#34;&gt;1.11&lt;/span&gt;&lt;span class=&#34;number&#34;&gt;.1&lt;/span&gt;&lt;span class=&#34;number&#34;&gt;.6&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;      - nvidia-curand-cu12==&lt;span class=&#34;number&#34;&gt;10.3&lt;/span&gt;&lt;span class=&#34;number&#34;&gt;.7&lt;/span&gt;&lt;span class=&#34;number&#34;&gt;.77&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;      - nvidia-cusolver-cu12==&lt;span class=&#34;number&#34;&gt;11.7&lt;/span&gt;&lt;span class=&#34;number&#34;&gt;.1&lt;/span&gt;&lt;span class=&#34;number&#34;&gt;.2&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;      - nvidia-cusparse-cu12==&lt;span class=&#34;number&#34;&gt;12.5&lt;/span&gt;&lt;span class=&#34;number&#34;&gt;.4&lt;/span&gt;&lt;span class=&#34;number&#34;&gt;.2&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;      - nvidia-cusparselt-cu12==&lt;span class=&#34;number&#34;&gt;0.6&lt;/span&gt;&lt;span class=&#34;number&#34;&gt;.3&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;      - nvidia-nccl-cu12==&lt;span class=&#34;number&#34;&gt;2.26&lt;/span&gt;&lt;span class=&#34;number&#34;&gt;.2&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;      - nvidia-nvjitlink-cu12==&lt;span class=&#34;number&#34;&gt;12.6&lt;/span&gt;&lt;span class=&#34;number&#34;&gt;.85&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;      - nvidia-nvtx-cu12==&lt;span class=&#34;number&#34;&gt;12.6&lt;/span&gt;&lt;span class=&#34;number&#34;&gt;.77&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;      - packaging==&lt;span class=&#34;number&#34;&gt;25.0&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;      - pandas==&lt;span class=&#34;number&#34;&gt;2.2&lt;/span&gt;&lt;span class=&#34;number&#34;&gt;.3&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;      - propcache==&lt;span class=&#34;number&#34;&gt;0.3&lt;/span&gt;&lt;span class=&#34;number&#34;&gt;.1&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;      - psutil==&lt;span class=&#34;number&#34;&gt;7.0&lt;/span&gt;&lt;span class=&#34;number&#34;&gt;.0&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;      - pyarrow==&lt;span class=&#34;number&#34;&gt;20.0&lt;/span&gt;&lt;span class=&#34;number&#34;&gt;.0&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;      - python-dateutil==&lt;span class=&#34;number&#34;&gt;2.9&lt;/span&gt;&lt;span class=&#34;number&#34;&gt;.0&lt;/span&gt;.post0&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;      - pytz==&lt;span class=&#34;number&#34;&gt;2025.2&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;      - pyyaml==&lt;span class=&#34;number&#34;&gt;6.0&lt;/span&gt;&lt;span class=&#34;number&#34;&gt;.2&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;      - regex==&lt;span class=&#34;number&#34;&gt;2024.11&lt;/span&gt;&lt;span class=&#34;number&#34;&gt;.6&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;      - requests==&lt;span class=&#34;number&#34;&gt;2.32&lt;/span&gt;&lt;span class=&#34;number&#34;&gt;.3&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;      - safetensors==&lt;span class=&#34;number&#34;&gt;0.5&lt;/span&gt;&lt;span class=&#34;number&#34;&gt;.3&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;      - six==&lt;span class=&#34;number&#34;&gt;1.17&lt;/span&gt;&lt;span class=&#34;number&#34;&gt;.0&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;      - sympy==&lt;span class=&#34;number&#34;&gt;1.14&lt;/span&gt;&lt;span class=&#34;number&#34;&gt;.0&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;      - tokenizers==&lt;span class=&#34;number&#34;&gt;0.21&lt;/span&gt;&lt;span class=&#34;number&#34;&gt;.1&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;      - torch==&lt;span class=&#34;number&#34;&gt;2.7&lt;/span&gt;&lt;span class=&#34;number&#34;&gt;.0&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;      - tqdm==&lt;span class=&#34;number&#34;&gt;4.67&lt;/span&gt;&lt;span class=&#34;number&#34;&gt;.1&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;      - transformers==&lt;span class=&#34;number&#34;&gt;4.51&lt;/span&gt;&lt;span class=&#34;number&#34;&gt;.3&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;      - triton==&lt;span class=&#34;number&#34;&gt;3.3&lt;/span&gt;&lt;span class=&#34;number&#34;&gt;.0&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;      - typing-extensions==&lt;span class=&#34;number&#34;&gt;4.13&lt;/span&gt;&lt;span class=&#34;number&#34;&gt;.2&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;      - tzdata==&lt;span class=&#34;number&#34;&gt;2025.2&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;      - urllib3==&lt;span class=&#34;number&#34;&gt;2.4&lt;/span&gt;&lt;span class=&#34;number&#34;&gt;.0&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;      - xxhash==&lt;span class=&#34;number&#34;&gt;3.5&lt;/span&gt;&lt;span class=&#34;number&#34;&gt;.0&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;      - yarl==&lt;span class=&#34;number&#34;&gt;1.20&lt;/span&gt;&lt;span class=&#34;number&#34;&gt;.0&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;figure class=&#34;highlight python&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;15&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;16&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;17&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;18&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;19&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;20&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;21&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;22&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;23&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;24&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;25&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;26&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;27&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;28&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;29&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;30&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;31&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;32&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;33&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;34&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;35&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;36&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;37&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;38&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;39&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;40&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;41&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;42&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;43&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;44&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;45&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;46&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;47&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;48&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;49&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;50&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;51&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;52&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;53&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;54&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;55&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;56&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;57&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;58&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;59&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;60&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;61&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;62&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;63&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;64&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;65&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;66&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;67&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;68&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;69&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;70&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;71&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;72&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;73&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;74&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;75&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;76&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;77&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;78&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;79&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;80&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;81&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;82&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;83&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;84&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;85&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;86&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;87&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;88&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;89&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;90&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;91&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;92&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;93&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;94&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;95&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;96&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;97&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;98&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;99&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;100&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;101&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;102&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;103&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;104&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;105&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;106&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;107&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;108&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;109&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;110&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;111&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;112&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;113&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;114&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;115&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;116&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;117&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;118&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;119&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;120&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;121&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;122&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;123&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;124&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;125&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;126&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;127&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;128&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;129&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;130&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;131&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;132&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;133&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;134&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;135&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;136&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;137&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;138&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;139&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;140&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;141&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;142&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;143&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;144&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;145&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;146&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;147&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;148&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;149&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;150&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;151&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;152&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;153&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;154&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;155&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;156&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;157&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;158&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;159&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;160&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;161&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;162&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;163&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;164&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;165&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;166&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;167&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;168&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;169&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;170&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;171&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;from&lt;/span&gt; transformers &lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; BertTokenizerFast,BertConfig,BertForMaskedLM,DataCollatorForLanguageModeling,TrainingArguments,Trainer&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;from&lt;/span&gt; datasets &lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; load_dataset&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;from&lt;/span&gt; tokenizers &lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; BertWordPieceTokenizer&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; torch&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; os&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; json&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;from&lt;/span&gt; itertools &lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; chain&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; os&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;os.environ[&lt;span class=&#34;string&#34;&gt;&amp;#x27;CUDA_VISIBLE_DEVICES&amp;#x27;&lt;/span&gt;] = &lt;span class=&#34;string&#34;&gt;&amp;#x27;2&amp;#x27;&lt;/span&gt; &lt;span class=&#34;comment&#34;&gt;# 这个得加，多gpu跑的话会有问题&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 加载本地数据&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;wiki = load_dataset(&lt;span class=&#34;string&#34;&gt;&amp;quot;/data/hcfeng/learnLLM/wikipedia&amp;quot;&lt;/span&gt;, &lt;span class=&#34;string&#34;&gt;&amp;quot;20220301.en&amp;quot;&lt;/span&gt;, split=&lt;span class=&#34;string&#34;&gt;&amp;quot;train&amp;quot;&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;#仅保留text列&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;wiki = wiki.remove_columns([col &lt;span class=&#34;keyword&#34;&gt;for&lt;/span&gt; col &lt;span class=&#34;keyword&#34;&gt;in&lt;/span&gt; wiki.column_names &lt;span class=&#34;keyword&#34;&gt;if&lt;/span&gt; col!=&lt;span class=&#34;string&#34;&gt;&amp;quot;text&amp;quot;&lt;/span&gt;])&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;#切割数据&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;dataset = wiki&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;d = dataset.train_test_split(train_size=&lt;span class=&#34;number&#34;&gt;0.9&lt;/span&gt;,test_size=&lt;span class=&#34;number&#34;&gt;0.1&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;dataset_to_text&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;dataset,filename&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    outpur_path=&lt;span class=&#34;string&#34;&gt;&amp;quot;/data/hcfeng/learnLLM/TrainBert/small_dataset/&amp;quot;&lt;/span&gt;+filename &lt;span class=&#34;comment&#34;&gt;#拼接地址&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;with&lt;/span&gt; &lt;span class=&#34;built_in&#34;&gt;open&lt;/span&gt;(outpur_path,&lt;span class=&#34;string&#34;&gt;&amp;#x27;w&amp;#x27;&lt;/span&gt;) &lt;span class=&#34;keyword&#34;&gt;as&lt;/span&gt; f:&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;keyword&#34;&gt;for&lt;/span&gt; t &lt;span class=&#34;keyword&#34;&gt;in&lt;/span&gt; dataset[&lt;span class=&#34;string&#34;&gt;&amp;#x27;text&amp;#x27;&lt;/span&gt;]:&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            &lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(t,file=f)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;dataset_to_text(d[&lt;span class=&#34;string&#34;&gt;&amp;#x27;train&amp;#x27;&lt;/span&gt;],&lt;span class=&#34;string&#34;&gt;&amp;#x27;train.txt&amp;#x27;&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;dataset_to_text(d[&lt;span class=&#34;string&#34;&gt;&amp;#x27;test&amp;#x27;&lt;/span&gt;],&lt;span class=&#34;string&#34;&gt;&amp;#x27;test.txt&amp;#x27;&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;special_tokens = [&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;string&#34;&gt;&amp;quot;[PAD]&amp;quot;&lt;/span&gt;, &lt;span class=&#34;string&#34;&gt;&amp;quot;[UNK]&amp;quot;&lt;/span&gt;, &lt;span class=&#34;string&#34;&gt;&amp;quot;[CLS]&amp;quot;&lt;/span&gt;, &lt;span class=&#34;string&#34;&gt;&amp;quot;[SEP]&amp;quot;&lt;/span&gt;, &lt;span class=&#34;string&#34;&gt;&amp;quot;[MASK]&amp;quot;&lt;/span&gt;, &lt;span class=&#34;string&#34;&gt;&amp;quot;&amp;lt;S&amp;gt;&amp;quot;&lt;/span&gt;, &lt;span class=&#34;string&#34;&gt;&amp;quot;&amp;lt;T&amp;gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;]&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 如果根据训练和测试两个集合训练词元分析器，则需要修改files&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# files = [&amp;quot;train.txt&amp;quot;, &amp;quot;test.txt&amp;quot;]&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 仅根据训练集合训练词元分析器&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;files = [&lt;span class=&#34;string&#34;&gt;&amp;quot;/data/hcfeng/learnLLM/TrainBert/small_dataset/train.txt&amp;quot;&lt;/span&gt;]&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# BERT中采用的默认词表大小为30522，可以随意修改&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;vocab_size = &lt;span class=&#34;number&#34;&gt;30522&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 最大序列长度，该值越小，训练速度越快&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;max_length = &lt;span class=&#34;number&#34;&gt;512&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 是否将长样本截断&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;truncate_longer_samples = &lt;span class=&#34;literal&#34;&gt;True&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 初始化WordPiece词元分析器&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;tokenizer = BertWordPieceTokenizer()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 训练词元分析器，设定的 vocab_size 是最大允许值，但实际生成的词表大小可能更小&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;tokenizer.train(files=files, vocab_size=vocab_size, special_tokens=special_tokens) &lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 允许截断达到最大512个词元&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;tokenizer.enable_truncation(max_length=max_length)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;model_path = &lt;span class=&#34;string&#34;&gt;&amp;quot;/data/hcfeng/learnLLM/TrainBert/small_pretrained-bert&amp;quot;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 如果文件夹不存在，则先创建文件夹&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;if&lt;/span&gt; &lt;span class=&#34;keyword&#34;&gt;not&lt;/span&gt; os.path.isdir(model_path):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    os.mkdir(model_path)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 保存词元分析器模型&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;tokenizer.save_model(model_path)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 将一些词元分析器中的配置保存到配置文件，包括特殊词元、转换为小写、最大序列长度等&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;with&lt;/span&gt; &lt;span class=&#34;built_in&#34;&gt;open&lt;/span&gt;(os.path.join(model_path, &lt;span class=&#34;string&#34;&gt;&amp;quot;config.json&amp;quot;&lt;/span&gt;), &lt;span class=&#34;string&#34;&gt;&amp;quot;w&amp;quot;&lt;/span&gt;) &lt;span class=&#34;keyword&#34;&gt;as&lt;/span&gt; f:&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    tokenizer_cfg = &amp;#123;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;string&#34;&gt;&amp;quot;do_lower_case&amp;quot;&lt;/span&gt;: &lt;span class=&#34;literal&#34;&gt;True&lt;/span&gt;,&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;string&#34;&gt;&amp;quot;unk_token&amp;quot;&lt;/span&gt;: &lt;span class=&#34;string&#34;&gt;&amp;quot;[UNK]&amp;quot;&lt;/span&gt;,&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;string&#34;&gt;&amp;quot;sep_token&amp;quot;&lt;/span&gt;: &lt;span class=&#34;string&#34;&gt;&amp;quot;[SEP]&amp;quot;&lt;/span&gt;,&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;string&#34;&gt;&amp;quot;pad_token&amp;quot;&lt;/span&gt;: &lt;span class=&#34;string&#34;&gt;&amp;quot;[PAD]&amp;quot;&lt;/span&gt;,&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;string&#34;&gt;&amp;quot;cls_token&amp;quot;&lt;/span&gt;: &lt;span class=&#34;string&#34;&gt;&amp;quot;[CLS]&amp;quot;&lt;/span&gt;,&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;string&#34;&gt;&amp;quot;mask_token&amp;quot;&lt;/span&gt;: &lt;span class=&#34;string&#34;&gt;&amp;quot;[MASK]&amp;quot;&lt;/span&gt;,&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;string&#34;&gt;&amp;quot;model_max_length&amp;quot;&lt;/span&gt;: max_length,&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;string&#34;&gt;&amp;quot;max_len&amp;quot;&lt;/span&gt;: max_length,&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    json.dump(tokenizer_cfg, f)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# tokenizer处理序列会自动添加CLS和SEP，但是tokenizer.tokenize()只会进行基础分词，不会添加特殊分词&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;tokenizer = BertTokenizerFast.from_pretrained(&lt;span class=&#34;string&#34;&gt;&amp;#x27;/data/hcfeng/learnLLM/TrainBert/small_pretrained-bert&amp;#x27;&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(&lt;span class=&#34;string&#34;&gt;f&amp;#x27;tokenier:&lt;span class=&#34;subst&#34;&gt;&amp;#123;tokenizer&amp;#125;&lt;/span&gt;&amp;#x27;&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;encode_with_truncation&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;examples&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;string&#34;&gt;&amp;quot;&amp;quot;&amp;quot; 使用词元分析对句子进行处理并截断的映射函数（Mapping function）&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;return&lt;/span&gt; tokenizer(examples[&lt;span class=&#34;string&#34;&gt;&amp;quot;text&amp;quot;&lt;/span&gt;], truncation=&lt;span class=&#34;literal&#34;&gt;True&lt;/span&gt;, padding=&lt;span class=&#34;string&#34;&gt;&amp;quot;max_length&amp;quot;&lt;/span&gt;,max_length=max_length, return_special_tokens_mask=&lt;span class=&#34;literal&#34;&gt;True&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;encode_without_truncation&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;examples&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;string&#34;&gt;&amp;quot;&amp;quot;&amp;quot; 使用词元分析对句子进行处理且不截断的映射函数（Mapping function）&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;return&lt;/span&gt; tokenizer(examples[&lt;span class=&#34;string&#34;&gt;&amp;quot;text&amp;quot;&lt;/span&gt;], return_special_tokens_mask=&lt;span class=&#34;literal&#34;&gt;True&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 编码函数将依赖于truncate_longer_samples变量&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;encode = encode_with_truncation &lt;span class=&#34;keyword&#34;&gt;if&lt;/span&gt; truncate_longer_samples &lt;span class=&#34;keyword&#34;&gt;else&lt;/span&gt; encode_without_truncation&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 对训练数据集进行分词处理&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;train_dataset = d[&lt;span class=&#34;string&#34;&gt;&amp;quot;train&amp;quot;&lt;/span&gt;].&lt;span class=&#34;built_in&#34;&gt;map&lt;/span&gt;(encode, batched=&lt;span class=&#34;literal&#34;&gt;True&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 对测试数据集进行分词处理&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;test_dataset = d[&lt;span class=&#34;string&#34;&gt;&amp;quot;test&amp;quot;&lt;/span&gt;].&lt;span class=&#34;built_in&#34;&gt;map&lt;/span&gt;(encode, batched=&lt;span class=&#34;literal&#34;&gt;True&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;if&lt;/span&gt; truncate_longer_samples:&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;comment&#34;&gt;# 移除其他列，将input_ids和attention_mask设置为PyTorch张量&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    train_dataset.set_format(&lt;span class=&#34;built_in&#34;&gt;type&lt;/span&gt;=&lt;span class=&#34;string&#34;&gt;&amp;quot;torch&amp;quot;&lt;/span&gt;, columns=[&lt;span class=&#34;string&#34;&gt;&amp;quot;input_ids&amp;quot;&lt;/span&gt;, &lt;span class=&#34;string&#34;&gt;&amp;quot;attention_mask&amp;quot;&lt;/span&gt;])&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    test_dataset.set_format(&lt;span class=&#34;built_in&#34;&gt;type&lt;/span&gt;=&lt;span class=&#34;string&#34;&gt;&amp;quot;torch&amp;quot;&lt;/span&gt;, columns=[&lt;span class=&#34;string&#34;&gt;&amp;quot;input_ids&amp;quot;&lt;/span&gt;, &lt;span class=&#34;string&#34;&gt;&amp;quot;attention_mask&amp;quot;&lt;/span&gt;])&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;else&lt;/span&gt;:&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;comment&#34;&gt;# 移除其他列，将它们保留为Python列表&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    test_dataset.set_format(columns=[&lt;span class=&#34;string&#34;&gt;&amp;quot;input_ids&amp;quot;&lt;/span&gt;, &lt;span class=&#34;string&#34;&gt;&amp;quot;attention_mask&amp;quot;&lt;/span&gt;, &lt;span class=&#34;string&#34;&gt;&amp;quot;special_tokens_mask&amp;quot;&lt;/span&gt;])&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    train_dataset.set_format(columns=[&lt;span class=&#34;string&#34;&gt;&amp;quot;input_ids&amp;quot;&lt;/span&gt;, &lt;span class=&#34;string&#34;&gt;&amp;quot;attention_mask&amp;quot;&lt;/span&gt;, &lt;span class=&#34;string&#34;&gt;&amp;quot;special_tokens_mask&amp;quot;&lt;/span&gt;])&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 用于不截断的情况&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;group_texts&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;examples&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;comment&#34;&gt;# 拼接所有文本&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    concatenated_examples = &amp;#123;k: &lt;span class=&#34;built_in&#34;&gt;list&lt;/span&gt;(chain(*examples[k])) &lt;span class=&#34;keyword&#34;&gt;for&lt;/span&gt; k &lt;span class=&#34;keyword&#34;&gt;in&lt;/span&gt; examples.keys()&amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    total_length = &lt;span class=&#34;built_in&#34;&gt;len&lt;/span&gt;(concatenated_examples[&lt;span class=&#34;built_in&#34;&gt;list&lt;/span&gt;(examples.keys())[&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;]])&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;comment&#34;&gt;# 舍弃了剩余部分，如果模型支持填充而不是舍弃，则可以根据需要自定义这部分&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;if&lt;/span&gt; total_length &amp;gt;= max_length:&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        total_length = (total_length // max_length) * max_length&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;comment&#34;&gt;# 按照最大长度分割成块&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    result = &amp;#123;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    k: [t[i : i + max_length] &lt;span class=&#34;keyword&#34;&gt;for&lt;/span&gt; i &lt;span class=&#34;keyword&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;built_in&#34;&gt;range&lt;/span&gt;(&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;, total_length, max_length)]&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;for&lt;/span&gt; k, t &lt;span class=&#34;keyword&#34;&gt;in&lt;/span&gt; concatenated_examples.items()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;return&lt;/span&gt; result&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;if&lt;/span&gt; &lt;span class=&#34;keyword&#34;&gt;not&lt;/span&gt; truncate_longer_samples:&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    train_dataset = train_dataset.&lt;span class=&#34;built_in&#34;&gt;map&lt;/span&gt;(group_texts, batched=&lt;span class=&#34;literal&#34;&gt;True&lt;/span&gt;,desc=&lt;span class=&#34;string&#34;&gt;f&amp;quot;Grouping texts in chunks of &lt;span class=&#34;subst&#34;&gt;&amp;#123;max_length&amp;#125;&lt;/span&gt;&amp;quot;&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    test_dataset = test_dataset.&lt;span class=&#34;built_in&#34;&gt;map&lt;/span&gt;(group_texts, batched=&lt;span class=&#34;literal&#34;&gt;True&lt;/span&gt;,desc=&lt;span class=&#34;string&#34;&gt;f&amp;quot;Grouping texts in chunks of &lt;span class=&#34;subst&#34;&gt;&amp;#123;max_length&amp;#125;&lt;/span&gt;&amp;quot;&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;comment&#34;&gt;# 将它们从列表转换为PyTorch张量&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    train_dataset.set_format(&lt;span class=&#34;string&#34;&gt;&amp;quot;torch&amp;quot;&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    test_dataset.set_format(&lt;span class=&#34;string&#34;&gt;&amp;quot;torch&amp;quot;&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 开始训练&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(&lt;span class=&#34;string&#34;&gt;f&amp;quot;tokenizer.vocab_size:&lt;span class=&#34;subst&#34;&gt;&amp;#123;tokenizer.vocab_size&amp;#125;&lt;/span&gt;&amp;quot;&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;#这里vocab_size一般设为tokenizer.vocab_size，其实只要大于这个数字都是可以的，只是会占用了显存空间（training)，但是不能设小，会出现索引越界的问题&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;model_config = BertConfig(vocab_size=tokenizer.vocab_size, max_position_embeddings=max_length) &lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;model = BertForMaskedLM(config=model_config)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;data_collator = DataCollatorForLanguageModeling(&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    tokenizer=tokenizer, mlm=&lt;span class=&#34;literal&#34;&gt;True&lt;/span&gt;, mlm_probability=&lt;span class=&#34;number&#34;&gt;0.2&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;training_args = TrainingArguments(&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    output_dir=model_path, &lt;span class=&#34;comment&#34;&gt;# 输出目录，用于保存模型检查点&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    eval_strategy=&lt;span class=&#34;string&#34;&gt;&amp;quot;steps&amp;quot;&lt;/span&gt;, &lt;span class=&#34;comment&#34;&gt;# 每隔`logging_steps`步进行一次评估&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    overwrite_output_dir=&lt;span class=&#34;literal&#34;&gt;True&lt;/span&gt;,&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    num_train_epochs=&lt;span class=&#34;number&#34;&gt;100&lt;/span&gt;, &lt;span class=&#34;comment&#34;&gt;# 训练时的轮数，可以根据需要进行调整&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    per_device_train_batch_size=&lt;span class=&#34;number&#34;&gt;10&lt;/span&gt;, &lt;span class=&#34;comment&#34;&gt;# 训练批量大小，可以根据GPU内存容量将其设置得尽可能大&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    gradient_accumulation_steps=&lt;span class=&#34;number&#34;&gt;8&lt;/span&gt;, &lt;span class=&#34;comment&#34;&gt;# 在更新权重之前累积梯度&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    per_device_eval_batch_size=&lt;span class=&#34;number&#34;&gt;64&lt;/span&gt;, &lt;span class=&#34;comment&#34;&gt;# 评估批量大小&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    logging_steps=&lt;span class=&#34;number&#34;&gt;1000&lt;/span&gt;, &lt;span class=&#34;comment&#34;&gt;# 每隔1000步进行一次评估，记录并保存模型检查点&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    save_steps=&lt;span class=&#34;number&#34;&gt;1000&lt;/span&gt;,&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;comment&#34;&gt;# load_best_model_at_end=True, # 是否在训练结束时加载最佳模型（根据损失）&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;comment&#34;&gt;# save_total_limit=3, # 如果磁盘空间有限，则可以限制只保存3个模型权重&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;trainer = Trainer(&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    model=model,&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    args=training_args,&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    data_collator=data_collator,&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    train_dataset=train_dataset,&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    eval_dataset=test_dataset,&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;#检查点&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(&lt;span class=&#34;string&#34;&gt;&amp;quot;input_ids dtype:&amp;quot;&lt;/span&gt;, train_dataset[&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;][&lt;span class=&#34;string&#34;&gt;&amp;quot;input_ids&amp;quot;&lt;/span&gt;].dtype)  &lt;span class=&#34;comment&#34;&gt;# 应该是 torch.int64 (long)&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(&lt;span class=&#34;string&#34;&gt;&amp;quot;attention_mask dtype:&amp;quot;&lt;/span&gt;, train_dataset[&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;][&lt;span class=&#34;string&#34;&gt;&amp;quot;attention_mask&amp;quot;&lt;/span&gt;].dtype)  &lt;span class=&#34;comment&#34;&gt;# 应该是 torch.int64 (long)&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;batch = data_collator([train_dataset[&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;], train_dataset[&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;]])&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(&lt;span class=&#34;string&#34;&gt;&amp;quot;input_ids shape:&amp;quot;&lt;/span&gt;, batch[&lt;span class=&#34;string&#34;&gt;&amp;quot;input_ids&amp;quot;&lt;/span&gt;].shape)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(&lt;span class=&#34;string&#34;&gt;f&amp;#x27;batch[&amp;quot;input_ids&amp;quot;]:&lt;span class=&#34;subst&#34;&gt;&amp;#123;batch[&lt;span class=&#34;string&#34;&gt;&amp;quot;input_ids&amp;quot;&lt;/span&gt;]&amp;#125;&lt;/span&gt;&amp;#x27;&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(&lt;span class=&#34;string&#34;&gt;&amp;quot;labels shape:&amp;quot;&lt;/span&gt;, batch[&lt;span class=&#34;string&#34;&gt;&amp;quot;labels&amp;quot;&lt;/span&gt;].shape)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# print(&amp;quot;labels min/max:&amp;quot;, torch.min(batch[&amp;quot;labels&amp;quot;]), torch.max(batch[&amp;quot;labels&amp;quot;]))&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(&lt;span class=&#34;string&#34;&gt;&amp;quot;input_ids min/max:&amp;quot;&lt;/span&gt;, torch.&lt;span class=&#34;built_in&#34;&gt;min&lt;/span&gt;(batch[&lt;span class=&#34;string&#34;&gt;&amp;quot;input_ids&amp;quot;&lt;/span&gt;]), torch.&lt;span class=&#34;built_in&#34;&gt;max&lt;/span&gt;(batch[&lt;span class=&#34;string&#34;&gt;&amp;quot;input_ids&amp;quot;&lt;/span&gt;]))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(torch.__version__)  &lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(torch.version.cuda)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(torch.cuda.is_available()) &lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 训练模型&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;trainer.train()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
 ]]></description>
        </item>
    </channel>
</rss>
